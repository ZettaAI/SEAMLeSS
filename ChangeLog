CHANGES
=======

* made invert work
* initial commit for invert
* Debug training (#117)
* update docker, fix compose\_and\_render (#114)
* Use torchfields functions instead of utilities.helpers (#112)
* Update params for FAFBv15 samples (#113)
* Inspect FAFBv15 montages
* params: updated minnie fine model
* model added, preprocessing doesnt work
* Add create\_info flag to CloudManager & update render.py to use it
* Factor out displacement fields into a separate repository (#108)
* Update params
* DisplacementField: minor bug fixes, refactors, and comments
* Safe division to avoid NaNs during backward pass
* Use winding number to test inclusion rather than bounding i,j
* Epsilon for comparison to zero
* Autopad functionality in left inverse
* More efficient left inverse using sparse tensors
* Mean finite vector function
* Inefficient implementation of left inverse
* Function to list gpu tensors tracked by garbage collecter
* Add DisplacementField class to abstract displacement field operations
* Speed up Gaussian blurring by removing unnecessary copying
* Fix type issue when git call fails in ModelArchive (#107)
* Update cpc script to follow latest convention
* Update render script to use no prefix & operate locally
* Adjust cloudsample\_image to use max mip of image & field mip
* Update cpc with cv paths and no prefix
* Add copy\_mask script to overwrite one section with another
* Add fill\_bbox script
* Fix stitch offset calculation for final vector vote
* Update Dockerfile.gpu with git init command
* Add .git to .dockerignore
* Update requirements with six constraint
* Update params
* Fix bugs in stitch\_blocks
* Release align\_blocks with block & stitching alignments
* Update cloudsample\_multi\_compose for single fields & fix pad bug
* Fix stitching alignment in align\_blocks; comment out block alignment for now
* Hold on stitching alignment in align\_blocks
* fix bad default commit value (#105)
* Fix bugs in align\_blocks
* Fix typos in tasks
* Update params
* Add script to run summary tasks, then compile restuls
* Update params
* Refactor align\_blocks & stitch\_blocks
* Refactor align\_blocks for dynamic blocks based on per section params
* Remove prefix arg from all aligner schedulers
* Remove prefix arg from all tasks
* Adjust padded\_bbox max mip in compute field
* Add summarize task to compute simple stats for a chunk
* Update bbox stringify with z\_start & z\_stop args
* Remove done files from all tasks
* Change compute\_fcorr output to fixed dim of 128
* Add hardcoded blur & softmin to align\_blocks
* Update align\_blocks for dynamic vvote & skipped sections
* Update test params
* Account for device in get\_data
* Update fcorr for updated cloudmanager
* Add binary dilation task & script
* Add Threshold task & script
* Remove sum\_pool from find\_seams
* Fix bugs in find\_seams
* Add device=cpu to find\_seams script
* Add device arg for aligner to specify cuda or cpu
* Start migrating sum\_pool over to torch pooling
* Pass device arg to laplacian loss
* Break find\_seams into compute\_smoothness & sum\_pool
* Update find\_seams script based on field smoothness
* Include compute\_smoothness in the aligner based on Laplacian
* Update CopyTask & FindSeamsTask for summing & rechunking
* Update cloudmanager create\_info with sufficient offset for max\_mip & consistent chunk\_size
* Base find\_seams on skimage & summarize to MIP12
* Create find\_seams task
* Comment out done files for masking tasks
* Remove wait from mask\_logic
* Remove join of image to dst directory
* Add dilation to make\_fcorr\_masks; Clean up mask\_logic
* Update mask\_logic script
* Simplify mask ops into disjunction & conjunction methods from single MaskLogicTask
* clean mask operations
* Update params
* Fix copy field task generator bug
* Fix bugs in stitch\_blocks for surgical procedures
* Fix path bug in copy\_blocks
* Add copy\_blocks for transferring surgical blocks
* Update params
* Remove unused cloudvolumes from align\_blocks
* Update params
* Update params
* Update stitch\_blocks for non-contiguous rework
* Fix bug in align\_blocks for non-contiguous blocks
* Add render script (compose\_and\_render minus the compose)
* Added the 2 missing ranges + 2 new sections to lookup (#100)
* Remove ntq\_stitch\_blocks in favor of stitch\_blocks
* Move ntq\_multi\_stitch\_blocks to stitch\_blocks
* Update align\_blocks to operate on non-contiguous blocks
* multi masks operation scripts
* multi masks operation
* Update params
* Add z\_range file & info\_path to compose\_and\_render
* Add copy back to align\_blocks
* Rename render\_at\_mip1
* Update render\_at\_mip1 to compose to the fine mip
* Ignore wait at end of compute\_fcorr
* Update make\_fcorr\_masks to take a list of images
* five masks script
* five masks operation
* fix bugs
* four mask operation
* Add fcorr\_conjunction to operate on the post-processed output
* Add script to call make\_fcorr\_masks
* Replace slip method with make\_fcorr\_masks
* Add params to fcorr tasks
* receive a list of z
* mask out the whole section
* update
* filterthree task
* cpu deploy
* minor fix
* logical or
* minor fix
* minor fix
* minor fix
* minor fix
* combine masks
* three mask operation script
* larger chunk size
* larger chunk size
* 3 masks operation wrapper
* deploy cpu
* 3 mask development
* core function of 3 masks opertaion
* cpu fcorr
* threshold change to 240
* Adjust stitch blocks for decay over multiple blocks
* Fix bug in switch from CloudCompose to CloudMultiCompose
* Fix return field in cloudsample multi compose
* Update ntq\_stitch\_blocks and render\_at\_mip1 scripts with changes
* Add factors parameter for multi-compose
* Rename cloud\_multi\_compose\_field to multi\_compose
* Add an optional factor for cloudsample composing fields
* Correct the affine in cloudsample\_compose to be before the fields
* Add tasks and scheduling for cloudsample multi-compose
* Add cloudsample\_multi\_compose to compose a list of fields
* threshold 180
* fix bug
* secure slip detection
* update
* Remove testing restriction (rendering only first 10 sections)
* Adjust stitch\_blocks for separate overlap & stitch vvote params
* Make softmin\_temp & blur\_sigma kwargs for vector vote
* Update forward & reverse compose
* Edit which prev\_fields are used in stitch\_blocks
* Add blur\_field & use with vector vote inputs
* Increase softmin temp back to original level
* Add suffix to stitch\_blocks for directory renaming
* Add copy field to stitch\_blocks
* modify script to recieve threshold parameters
* set mask threshold as parameters
* set device to cpu
* Start forward\_compose in stitch\_blocks
* Minnie65 run
* Add updated minnie fine params (#98)
* Additional cleanup of vector\_fixer30\_faster\_v01 architecture code
* Remove the lowest aligner module from vector\_fixer30\_faster\_v01
* Clean up architecture code in vector\_fixer30\_faster\_v01
* Add vector\_fixer30\_faster\_v01
* Add a script to time models
* Use grid\_sample in vector\_fixer30
* slip write on z-1
* ntq\_stitch\_blocks.py (#96)
* Update softmin temp calculation in vector\_vote\_chunk (#95)
* Affine update (#94)
* Move new alignment script to align\_blocks
* Adjust block stitching to correct drift from nets (#93)
* using torch.zero for binary masks
* mask op bug fix
* remove monkey patching from aligner.py
* add task queue version requirement
* local queue support
* New Net: sergiy\_m8m10\_03\_01\_mip\_10\_8\_new\_finetune
* local queue support
* parametrize distance of pairs to compute fcorr
* threshold change
* update the required task-queue version
* local queue supported
* using new task queue
* mask operations
* Coarse models (#85)
* modify fcorr test script
* add masks operations
* fcorr parameter tuning: better give inaccurate value than no value at all
* update requirements
* new task queue support in aligner.py
* cpu fcorr
* fixed scaling parameter
* master
* master
* cpu run for fcorr
* threshold change
* run on mulitple mip
* fixed threshold
* MIP 1 Rendering w/ support for different source dirs
* correct a typo
* add render at mip1 script
* fix bugs in cloudsample\_compose
* render at mip1
* merge new task queue to master
* fix bugs
* Call the displaced alignment
* Allow running displaced inference in compute\_field\_chunk
* Add function cloudsample\_compose for composing field CloudVolumes
* deploy
* correct printing error
* set src\_mask\_cv and tgt\_mask\_cv to path
* fix bugs
* deploy
* using new task queue
* Minnie10 fine model params
* Update new\_serial\_block\_multimodel\_compose.py
* Update new\_serial\_block\_multimodel\_compose.py
* test copy task
* using cv path instead of cv object
* get\_hp\_fcorr documentation (#82)
* Contiguous chunk boundaries with affine transform support (#87)
* deploy
* Fcorr new (#86)
* fcorr post-process value
* add threshold to fcorr
* merge fcorr with mater
* hotfix: pin moviepy (#83)
* Remove fold detector preprocessor (#81)
* fcorr: quick edit allowing threshold adjustment
* fcorr: optional fill\_value argument which can be helpful in noise-removal postprocessing
* more documentation
* fix bugs for fcorr and write test scripts
* New fine net ...\_thinner (#80)
* modify the code according to Nico's comment
* expand documentation
* Update params
* Add task limit to upsample\_render
* merge with latest master branch
* Allow grid sampling in batches
* Switch to using grid\_sample instead of gridsample\_residual
* Refactor gridsampling and vector field functions
* Reformat helpers.py
* Add params for serial alignment
* Fix affine to be strictly at MIP0 (#77)
*  Update encodings\_all\_samples\_mGPU\_c2e through epoch 784 iter 2553 (#76)
* Updated weights for fine model (#75)
* Add eps to correct avg\_field divide by zero (#72)
* Add print statements & chunk sizes to serial alignment
* Include drosophila bbox csv for test
* Add z args for serial block compose
* Increase sleep between counting finished tasks
* Fix typo in task\_counter logic
* Add blank image handling in get\_data
* Update drosophila bboxes
* Fix bounding box adjustments
* Update serial block multimodel compose to use z-dependent bboxes
* Fix args.py to use bbox\_mip
* Coarse models (#71)
* New fine model (#70)
* Faster normalizer for vector\_fixer\_30\_new\_normalizer (#69)
* New fine model update (#67)
* Add affine preconditioning to render (#68)
* Hard-code aligner's vector voting to be 2\*\*mip & require it for vector\_vote helper (#65)
* New fine MIP2 models (#64)
* Update mip4 aligner net encodings\_all\_samples\_mGPU\_c2e through epoch 767 (#60)
* Merging new fine net models. (#63)
* adding fine model sergiy\_m4m6m8\_zzzz\_02\_07\_mip\_4\_6\_8\_fold\_preproc\_sm1e6\_newmask (#62)
* merge with master branch
* Add updated minnie coarse models params (#61)
* Update docker deploy template (#59)
* Set fixed padding for cloudsample\_image (#58)
* Add arg for worker to specify lease time for tasks (#57)
* Add arg for worker to specify lease time for tasks
* n5 mdoels (#55)
* Adjust functions to pass max\_mip to break\_into\_chunks (#56)
* GPU semaphore (#51)
* Move SQS creation so only scheduler needs credentials (#54)
* Free up memory from vector\_fixer30 architecture (#53)
* Add back the SQS wait until queue is empty (#52)
* feat: composite target image using alternative images (#50)
* vectorize fcorr misalignment indicator computation
* cpu rendering support
* fix fine
* Coarse models (#47)
* fine babynet
* fine babynet
* Correct max\_displacement flag to pad for cpc
* Coarse models (#45)
* first specialized
* first specialized
* Peg cloudvolume (#44)
* Fix typos
* fix: DNS timeout (#43)
* commit info when creat cv
* commit info when creat cv
* Check if batch has anything to run at final stage
* Set chunksize in serial block multimodel compose
* Peg imageio version (#40)
* newer models (#41)
* Add new script to use model lookup & combine block alignment with composition
* Setup model lookup file for coarse run
* newer models
* correction
* Add NCCnet models (#39)
* Barebone "fcorr" misalignment indicator (#38)
* 19 models
* Fix aligner bugs to use fine net (#35)
* Add cpc script to run on even & odd blocks (#31)
* Make compose & cpc parallel across entire stack (#33)
* remove info file from message
* fix the upload\_tasks function issue for multi processes (#24)
* m
* Fix bug in weight loading for coarse models
* Multiple coarse models for testing (#34)
* forgot 1 model
* models
* test run for compute field and vector voting
* modify the script for compute field and vector vote
* fix bugs
* multi gpu support for fold detection
* merge with master branch
* Add a mip4 fine aligner and defect detector nets (#32)
* Tweak serial alignment for distributed speed (#30)
* Update docker
* Add masks back to compute\_field & fix get\_masked\_image
* Update poll lease\_seconds in worker
* new coarse model (#28)
* new coarse model
* Add compose decay (#27)
* load model key verification fixed
* Resolve deadlock when using  multiple processes (#25)
* readonly param change
* bug fixed!
* add sigmoid to fold model
* add fold detect function
* Switch alex\_fold\_detector\_norm\_mip4\_0131 to model66000
* Add alex\_fold\_detector\_norm\_mip4\_0131
* Change alex\_fold\_detector\_norm\_0130 to version model68000
* Bring back model\_exists archive class method
* Replace tabs with spaces
* Refactor archive path code
* Allow commit not to be specified
* Add alex\_fold\_detector\_norm\_0130
* using gpu to process vector voting
* fix bugs for calc res and vvote
* add res\_and\_vv script
* add res\_and\_vv function
* Multi-processing support for inference worker (#23)
* fix the upload\_tasks function issue for multi processes
* Include latest distributed serial alignment updates (#21)
* Int16 field (#20)
* fix bugs for distributed rechunking (#19)
* Add distributed regularization (compose, invert, & regularize) (#18)
* Get short-stretch regularization working
* multi-gpu code for rechunking
* rechunking and condsder identity field
* Add sergiy's inverter net
* Revert "Merge branch 'pairwise-align-across-archives-muti-gpu' of https://github.com/seung-lab/SEAMLeSS into pairwise-align-across-archives-muti-gpu"
* Fix bugs in inverting with the aligner
* Fix inverse task handling
* Update sergiy\_trans\_minnie\_v1\_m8m10 for multi-model loading
* Add vector\_fixer30 to output at MIP4
* Add inverter net
* Fix python-jsonschema-objects version
* Add model archiving and fresh training code (#12)
* Add section batching into multi-match
* inverter weights
* inverter module
* Update docker & kube files to accommodate setup.py
* Remove neuroglancer link provider to ignore bitly credential handling
* Allow loading multiple archives simultaneously
* Remove unnecessary args from worker & aligner for task listening
* Update gitignore for kube secrets
* mean value for grid\_sample and multi-gpu functions
* Kwargs in architecture code
* using mean value in CV grid\_sample
* fix bugs in grid\_sample cv
* Update provenance with more params
* Adjust z range in render\_low\_mip
* Fix vector field convention for aligner
* added coarse aligner net that is trained for vector voting
* using normal warp by default
* Cloudvolume grid\_sample
* changed the default mip for m6m8m10 model to 5
* removed unneeded models
* merged plastic masks
* cleanup
* gitignore
* plastic mask working
* Separate directory classes from aligner & convert vectors to numpy arrays before saving
* clean code and write new functions for multi-slice vector voting
* Checkout docker files from multi-gpu-pairwise
* first attempt and masker code
* fill\_missing set to True
* remove black block detection for test
* add loading black block detection
* fix print
* fix print
* fix bugs
* clean out garbage files for village internet
* fix bugs
* multiple slices vector voting
* exported plastic detector
* seperate render and downsample
* set write fill\_missing to false
* listen task in listen\_for\_tasks
* debuging for black blocks
* modify read\_kwargs
* set fill\_missing to false
* remove thread pool from render function
* remove pool for downsampling
* Fix bug in pairwise\_alignment
* Add optimizer, prand, state\_vars, and plot to checkpoint
* correct mask code for multi-gpu
* fixed trans
* Add pairwise\_alignment command for serial start & pairwise finish
* Fix vector voting bug in aligner for serial\_alignment
* trans nets
* one more net
* even more models
* moar models
* Fix mask handling
* Add provenance commit to mipless\_cloudvolume
* add flags for multi-gpu regularization in worker.py
* modify render\_low\_mip.py
* Add defaults for render\_low\_mip & render\_high\_mip in args.py
* Fix tgt\_range in aligner for serial\_alignment
* update upsampling
* fix
* new model
* Flag for toggling encodings
* random\_one occasionally trains all
* Factor out mask generation to objective code
* Move mask library to utilities
* Correct error in pixel size ratio calculation
* Remove redundant except clause
* Separate the stack images in the debug outputs
* Allow plot to start at non-zero position on time axis
* Move seed into state\_vars
* Convert state\_vars to YAML to support slices and other python objects
* Rewrite submodule and level selection
* Fix feature\_maps command line arg
* Add plan argument which can be all, top\_down, bottom\_up, or random\_one
* add forward and inverse compose flags back
* clean up
* multi-GPU interface for regular and invert
* fix bug for upsample
* Add compose\_invert\_regularize that includes creating optimized inverses
* Remove regularized\_cv & add dir\_suffix flag for regularization tests
* upsample vector at mip8 to mip2 and render
* fix bugs
* :wMerge branch 'pairwise-align-across-archives-muti-gpu' of https://github.com/seung-lab/SEAMLeSS into pairwise-align-across-archives-muti-gpu
* fix bugs
* Fix render-related mip flags in args.py
* Fix regularization across blocks
* Update inference to use regularized inverses to re-regularize overlap
* fix bugs
* upsampling and rendering at mip1
* add docker file
* fix bugs
* fix bugs
* add purge function for sqs
* fix coordinate issue in the NG link
* Setup serial alignment to copy & align initial sections
* Update aligner for blocker compose and regularization
* Update inverse loss function to MSE
* Revert render.py to operate only on root dir field
* Add debug script to compose two fields to test inverse quality
* Make compose and regularize operate in blocks over z\_range
* fix bugs
* Support for top-down or bottom-up training
* Add support for encodings in architecture
* Add a feature\_maps command line argument
* add serial alinger
* fix bugs
* Add vector field inverse based on optimization
* Correct bug in invert tests
* multi-gpu version
* Update invert tests
* Fix bug in invert & tests to account for x,y being stored as [N, Y, X, 2]
* Add tests for inverse method
* Start invert method to create inverse of a vector field
* Visualization after logging
* Use preprocessor from archive rather than built-in one
* Fix dataset indexing to allow multiple sequences per dataset
* Skip empty sections
* Add vector\_fixer30 as a ModelArchive using version e260\_t200
* Debug aligner for regularization & add client scripts
* Remove MiplessCloudVolume exist check
* Add Sergiy's Rollback Pyramid model
* Change multi\_match method call
* Debug aligner.py
* Update aligner.py for temporal regularization
* Add check if miplessCV exists to determine if mkdir needed
* Fix flip averaging bug
* Make z and z\_offset explicit parameters to aligner methods
* Fix some inference issues with archive
* Add one-off temporal regularization
* Update util.py for combined CloudVolumes for fields
* Remove spatial regularization from get\_composed\_field
* Incorporate model archive into inference
* Fix preprocessor code
* Redirect imports to utilities package
* Add noqa to matplotlib imports
* Move archive and helpers code to utilities package
* Allow objective and preprocessor to not exist
* Fix objective loading
* Factor out contrast normalization as an archive preprocessor
* Move ojective code into its own file
* Changes to allow running full net
* Finish making z, z\_offset explicit in aligner.py
* Debug aligner.py
* Debug pairwise align across
* Rename supervised\_train.py to train.py
* Update header comment for training code
* Move defect net weight files into a directory
* Remove old training code
* Remove unused lm and hm command line args
* Clean up archive code
* Visualize during validation and clean up training code
* Retry forking if it fails for lack of memory
* Factor out debugging outputs creation
* Wrap objective/loss function in a PyTorch module
* Allow # comments in loss.csv
* Allow self-supervised loss calculation on batches
* Perform validation in main process
* Debug
* Update CloudVolume handling in Aligner for pairwise vector voting
* Add class for MIP agnostic CloudVolume
* Create tensors directly on GPU
* Fix argument misspelling
* Move model saving/loading code to architecture
* Start aligner modifications for vector voting + pairwise
* Adjust vector vote to use pairwise
* Allow skipping levels
* Add simple timing decorator
* Allow random names wildcard for rapid testing
* Change state\_vars to a dotdict for easier notation
* Add masking for self-supervised training
* When training on batches, only visualize the first sample
* Redo normalizer and preprocessing to speed up training
* Bug fix for submodule initialization
* Simplify dataset loading
* Format validation loss better
* Fix resuming at same iteration
* Display validation progress
* Fix plotting bug
* Cache args in order not to parse them twice
* Start iteration bug fix
* Only deal with masks if they exist
* Add @torch.no\_grad() to prepare\_input
* Specify plotting columns as individual arguments
* Also copy over loss when initializing with a trained net
* Allow resuming from the middle of an epoch
* Stop initializing final layer when fine-tuning
* Don't output ground truth for unsupervised
* Add @torch.no\_grad() decorators
*  Add newest trained vf30
* Rewrite architecture code and clean up submodule API
* Add latest iteration of trained net vf30.pt
* Clean up model loading code
* Add capability to train using subset of aligners
* Use torch.chunk instead of torch.split
* Print the model name for recognition in terminal
* Unite all vector handling methods
* Slightly simplify architecture
* Bring back the random field generation
* Typo correction and default weight decay at 0
* Seed before model initialization
* Use random field of only three possible displacements
* Automatically find an unused GPU if not specified
* Update multi\_match to align serially with vector voting
* Update aligner loading, masking, weighting, & params
* Update aligner interfaces with abstracted args
* Fix boundingbox range & size incosistencies
* Update/add vector voting helper methods
* Update util permutes, names, & restrict new CV to single slice
* Add/update mask generation & compilation methods
* Separate common argparse methods & Aligner + BoundingBox creation
* Remove eval dir & move files into inference
* Change default parameters
* Give vector field printouts more meaningful titles
* Change history to a txt file
* Fix vector display bug
* Pretty-print state\_vars.json
* scipy gaussian blurring
* Also save at the beginning of each epoch
* Increase vector debug output magnification
* Record training iteration
* Clean up src/tgt debugging outputs
* Fix file output redirection
* Clean and comment training code
* Use saved batch size
* Redirect output to log file
* Allow disabling log, checkpoint, and vis intervals
* Add parameter for field generation
* Fix training code errors
* Use random sampler
* Allow serialization of pathlib Paths
* Rename helpers copy method to cp to avoid confusion with python copy
* Add function to set log titles
* Require training data, and make validation data optional
* Perform args processing before imports
* Fix model loading consistency
* using field\_sf with no\_anchor flag
* Save internal module from DataParallel abstraction
* Allow starting from other initialized nets
* Add pandas dependency
* Discourage overwriting the model name
* Add visualization of training curves
* Clean up code
* Add validation code
* Rename archive.update() to archive.save()
* Several updates to enable supervised training
* gaussian blurring refined
* gaussian blurring
* global mean reg
* refine code
* refine code: half done
* global regular
* Update training
* Update CPC main
* Initial commit of supervised training code
* Update architecture API
* Rename log\_time
* Add command and history to archive
* Add a state\_vars file to archive
* Update command line arguments
* Checkout aug.py from "multi-gpu"
* Checkout stack\_dataset.py from "multi-gpu"
* Rearrange archive code
* Finish model loading code
* no shift image for pairwise
* bug fix
* Clean up warp\_patch
* fix bugs
* incorporate pairwise
* Rename architecture template and modify API
* Factor out commit getter
* Prevent setting arbitrary names
* Add a system file copy to helpers.py
* Update archive.py
* Add a flag to accept a net trained with old vector conventions (#7)
* Checkout helpers.py from multi-gpu
* Hide the wrapper function for shutil.copy
* update .gitignore to ignore debugging outputs
* Initial commit of archiving code
* Add a module defining a command line API with tab completion
* Add argcomplete to requirements and add a sample setup script
* Add multi\_match to call aligner method & then run CPC
* Update aligner.py
* Include get\_bounding\_pts method to BoundingBox
* Make inference & eval modules
* Add CPC class for easier handling
* Refactor ng path handling into class dict
* Add match\_section to make match pair explicit
* Update aligner & add render\_section to use saved vector field
* Move eval dir & add field eval methods
* Add back grad disabling at inference time
* Fix PyramidTransformer merge
* Add pairs.py to specify src & tgt z
* Add Gaussian blur method in eval
* Add int8\_to\_norm for cpc
* Update cpc with z offset & reverse composite image (default)
* Fix more multi-gpu merge conflicts
* Update vis\_interval start & arg help
* Add log\_interval for training
* Add a flag to accept a net trained with old vector conventions (to ease the transition)
* Resolve multi-gpu merge conflicts
* Update eval README
* Remove earlier cpc
* Rewrite cpc using pytorch
* Print logging scalars as python numbers
* Fix visualization lookup
* Clean up helpers.py
* Put zero field on the same device as encodings
* Refactor grid sampling and identity grid in inference code
* Improve use of no\_grad and zeros
* Switch to new vector field convention in training code
* Use torch.no\_grad to disable computation graph at inference time
* Switch to using new grid sampler wrapper in pyramid.py
* Add grid sampling function for residuals
* Add size-agnostic grid sampling and identity grid generation functions to helpers.py
* Bring helpers.py closer together in training and inference
* Add proper error handling to loss.py
* Update stack\_dataset to also provide reverse image pairs
* Run single GPU training through data\_parallel
* Update training model identity with device
* Apply grid sampling changes at inference as well
* Fix saving intermediate models
* Fix border effects for aligner module grid sampler
* Correct augmentation by moving normalize last
* Make visualize\_outputs multi-gpu compatible
* Add back augmentation for translation, contrast, & cutouts
* Move augmentation to be dataset transforms
* Update defaul low mip source to cleaned drosophila data
* Save state every 100 log events
* Fix log outputs
* Move normalizer to dataloader & reorganize methods in epoch train loop
* Add clean\_stack to remove empty/low-info images from training data
* Be explicit about tensor device placement in pyramid & training
* Fix typos in train.py ModelWrapper
* Adjust stack\_dataset to output 2D tensors for src & tgt
* Update .gitignore for .swp
* Fix off-by-one in process.py
* add flag --skip and change default size to 8
* add flag --skip and change default size to 8
* Rework train.py & stack\_dataset.py for bugs
* Add matriarch\_tile7 and vector\_fixer11
* Rework train.py with ModelWrapper for multi-gpu
* Update DataLoader for minibatching & add flags for it
* Rework stack\_dataset to deliver consecutive image pair
* Remove defect net & related masks
* Add option to write out residuals and encodings (#5)
* Modify inspect README & requirements; remove unnecessary inspect files
* Update requirements for inspect
* Update eval/inspect for python neuroglancer package API
* Adjust fields under upsampling and grid sampling to account for non-size-agnostic conventions
* Allow direct printing of bboxes
* Undo indexing dimension adjustment
* Add flag '--old\_upsample' to revert to old upsampling method
* Fix training from scratch
* Add upsample helper method and check for None
* Update to accomodate dimension convention change for tensor indexing
* Change deprecated upsampling in defect net to interpolate
* Update architecture with optional flag to enable preencoder
* Fix torch type calls
* Change vector field addition to composition
* Convert all grid sampling to bilinear
* Remove temporary file
* Upgrade to the newest version of pytorch
* Add set\_mip & set\_path to inspect field
* Fix div-by-zero error in eval
* Add residual and encoding return values
* Add inspect for Neuroflow vector fields in eval
* Rename inference/client.py
* Remove unneeded files in Neuroflow-SEAMLeSS merge
* Move inference/requirements.txt and inference/setup.py
* New architecture and minor refactors
* Add option to run inference on consecutive pairs of input slices (#2)
* Fix argument triples in chuncked.py
* Update str to int for chunked.py argparse
* Add a flag for disabling the flip averaging
* Add averaging to correct any drift
* flip image
* Removed highpass from normalizer
* New model with tile training
* Added experimental drift-correction matriarch models
* Added latest matriarch
* Fixed unnecessary \* 2 in process.py
* Properly fixed type conversion
* Fixed improper numpy type conversion
* Added support for in-terminal Neuroglancer links; added missing dependencies to requirements.txt
* Minor refactors, new command line argument support
* Update requirements.txt
* Fixed missing mip levels issue for high mip inference
* Eric changes
* Patched bad backtracing (TODO:properly fix)
* Added models for inference
* Eric refactor
* Pre-multitarget
* Add chunked NCC evaluation method
* Migrate to python3 (+ minor refactors) (#3)
* Add a .gitignore file (#2)
* Minor fixes to README
* Added weight decay to supervised pre-encoder training
* Minor changes to fix bugs in pre-encoder only training
* More README updates, removed unused files unet2d.py and dnet.py
* More README updates
* More README updates
* Update README
* Combine requirements into one requirements.txt file
* Disabled weight normalization
* Fix bug on visualize\_outputs(None)
* Minor README addition
* Updated README (still in progress)
* update requirements.txt to reflect torch version
* Add command line args for training data location
* update requirements.txt
* update requirements.txt
* update requirements.txt
* Added test model
* Added partial requirements.txt; TODO: add missing requirements
* Minor refactors
* Updated README
* Updated README
* Updated README
* Fixed Python2 print statements
* Refactored visualization code, adjusted contrast augmentation semantics and increased maximum cut proportion
* Missing line of code in README
* Updated README with fine-tuning example
* Minor refactor in pyramid encoder feature map count calculation
* Added consensus field penalty masking for more useful gradient
* Added proper flipping consensus
* Merged from master
* Revised training for consensus penalty
* Reverted pyramid.py
* Made pe\_only training supervised
* Removed pe
* Residual net refinements
* Consensus refactor
* Heavy refactor, added tiling and gaussian noise augmentation, removing highpass contrasting, exlcluded pinky100 from training (tiling)
* Add requirements.txt
* Large refactor of defect detection, contrasting/normalization, mask logic, and dataset generation. Adjusted weighted random sampling. Added new vector field visualization (distortion grid)
* Added help messages for all parameters
* More refactoring, added grid line field visualization, added raw source mask visualization, added centered jacobian loss
* Included model archive
* Minor refactor of order of declarations in train.py
* Removed old flag arguments
* Minor consensus refactor. Changed default mask smoothing parameter
* Major refactor of train.py, added mask helper functions, added weighted draw to cutouts, moved smoothness inside run\_sample
* Switched to dense folds training for low mip, added double emphasis for defects in target
* Disabled residual field gif visualizations for performance reasons
* Minor rescaling refactor
* Major refactor, adding use of ceil for masks, adding mask helpers, and fixing unflow penalty. Fixed nan issue regarding weight normalization
* Removed name, unet, dilate, amp parameters
* Removed multitarget
* Refactoring visualization code
* Removed explicit crack\_fold\_mse\_mask
* Removed displace\_slice, simplified mask selection
* Updated aug, added center to helpers, added vis, removed pyramid select functions
* Moved requires\_grad = True inside load conditional, used only full\_father dataset, moved visualization to sample\_idx == 0
* Removed inference code
* Added missing import
* Refactored training to use defect detector net instead of static crack and fold masks
* Cleaned up augmentation, added rotational cutouts, increased missing data augmentation, added true multi-target support
* Contrasting adjustments, minor refactor for high mip/low mip dataset loading
* Fixed new vector field visualization, added support for converting residuals to gifs, adjusted MSE weighting in training, suppressed h5py warnings, added specific coordinates for cv\_sampler for folds in Basil
* Minor bug fixes
* Updated for separate crack and fold masks at different mip levels
* Refactored masks, added infrastructure for fold masks
* Resolved crack masking bug
* Added missing network definition for prednet
* Removed testing code for adversarial training
* Moved coords to within training directory
* Added coords for basil training data and masks
* Refactored into training directory, added support for crack detector masks
* Added matching to predictions, additional augmentation
* Resolved further patch size-related bugs
* Lingering issues related to size-invariant inference resolved
* Size invariant SEAMLeSS
* Added new crack model
* optimizer with an example added
* Updated default model size. Added new crack model
* Newest model upload
* Updated README
* Refactored to separate training and inference
* More minor refactoring
* Added relative dath path
* More refactoring
* Added missing UNet
* More refactoring, added previously-missing analysis helpers
* Minor refactoring
* Create README.md
* Changed gen\_stack source to be argument
* Initial commit
* cleaned junk
* Added retrained Jacob, fixed residuals (kind of)
* Added Jacob
* Adjusted client for convolutional pyramid
* Resolved abs\_res merge conflicts
* Added dilated network
* CUDNN support
* 1 min per section
* render/net different chunks
* Fixed model loading bug
* Changed to absolute displacements, added new models
* removed rel to abs conversion
* manual fixing
* separate residual layers
* threads flag added
* inference 2x faster
* basil model
* client
* fix for cavelab import
* upsample choice added
* unet3d
* 3D unet
* inference gsutil removed
* basil ready training
* model seperated and xmas added
* XmasTransformer model
* resolved
* timings
* sorry Sergiy, caught one mistake
* inference merge resolved (hopefully)
* resolved merge conflict
* hierarchical training works
* client
* all works
* gMerge branch 'master' of https://github.com/seung-lab/Neuroflow
* gMerge branch 'master' of https://github.com/seung-lab/Neuroflow
* identity bug fixed
* identity bug fixed
* refactor, new render
* refactor, new render
* m
* m
* save
* save
* fused working, but border effect
* fused working, but border effect
* training mip 6 working
* training mip 6 working
* python3 print
* python3 print
* Added new model, minor refactor to process to compensate for pyramids trained at mip other than 0
* Added new model, minor refactor to process to compensate for pyramids trained at mip other than 0
* augmentation added
* augmentation added
* xmas network
* sequence training
* somethings working
* somethings working
* download upload tested
* download upload tested
* refactor bbox
* refactor bbox
* sort of working, no render yet
* sort of working, no render yet
* carcase
* carcase
* Unet and xmas added
* Unet and xmas added
* Cropping added and improved bug v2 for duplicated pyramids
* pyramidtransformer renamed
* inference working
* simple process
* simple process added
* Added pyramid implementation, naming convention for model archives, and a basic archived model to use for testing
* inference added
* loss improved
* loss averaged over all layers
* skip layers added, vizualization improved
* bug improved
* gated learning
* training with labels
* labeling added, loss seperated
* clean workspaces
* simple model
* docker addition
* Crack and Folds working
* test case and vizualizations added
* readme modifs
* initial commit
