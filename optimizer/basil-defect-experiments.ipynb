{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting to fix cracks & folds in basil  \n",
    "Using the Optimizer to fix cracks & folds in basil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cloud-volume\n",
      "  Using cached https://files.pythonhosted.org/packages/96/39/dac6a9da64502176b00e445a591d1b6a23484fb585330073a4f965d16f97/cloud_volume-0.23.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.5/dist-packages (from cloud-volume)\n",
      "Requirement already satisfied: Pillow>=4.2.1 in /usr/local/lib/python3.5/dist-packages (from cloud-volume)\n",
      "Collecting tqdm (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/93/24/6ab1df969db228aed36a648a8959d1027099ce45fad67532b9673d533318/tqdm-4.23.4-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.3.0 (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/5b/c3/9b947e301e19bea75dc8c1fd3710eed5d2b31aa13ae13d5e38e891f784cc/protobuf-3.5.2.post1-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting boto3>=1.4.7 (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/0d/14f29bebb6f93362da511dd4299d0dee2fb19d294657ae2c1f4adfb930a6/boto3-1.7.28-py2.py3-none-any.whl\n",
      "Collecting json5==0.5.1 (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/4b/cf/050247dcd8000a8f2413d7932281991acba5bb72270f5f39d0a22c9b3074/json5-0.5.1-py2.py3-none-any.whl\n",
      "Collecting requests>=2.18.4 (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/49/df/50aa1999ab9bde74656c2919d9c0c085fd2b3775fd3eca826012bef76d8c/requests-2.18.4-py2.py3-none-any.whl\n",
      "Collecting google-cloud==0.32.0 (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/0a/49/03321cbc697d4aa97f74d87f1dc865ecdf05e4feb47f1c49b50573163a9c/google_cloud-0.32.0-py2.py3-none-any.whl\n",
      "Collecting six==1.10.0 (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/c8/0a/b6723e1bc4c516cb687841499455a8505b44607ab535be01091c0f24f079/six-1.10.0-py2.py3-none-any.whl\n",
      "Collecting urllib3[secure] (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/63/cb/6965947c13a94236f6d4b8223e21beb4d576dc72e8130bd7880f600839b8/urllib3-1.22-py2.py3-none-any.whl\n",
      "Collecting intern (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/85/aeb89f2a4f0339af67b7ad8d7330780e67aab1360e6444336a824f14eb80/intern-0.9.6-py2.py3-none-any.whl\n",
      "Collecting psutil==5.4.3 (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/e2/e1/600326635f97fee89bf8426fef14c5c29f4849c79f68fd79f433d8c1bd96/psutil-5.4.3.tar.gz\n",
      "Collecting backports-abc==0.5 (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/7d/56/6f3ac1b816d0cd8994e83d0c4e55bc64567532f7dc543378bd87f81cebc7/backports_abc-0.5-py2.py3-none-any.whl\n",
      "Collecting chardet==3.0.4 (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting python-jsonschema-objects==0.2.1 (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/1b/2ea3493d53da8fb2475fd0f11c5cd04c2910f12b5678af11cd9ee0de8727/python_jsonschema_objects-0.2.1-py2.py3-none-any.whl\n",
      "Collecting tenacity==4.4.0 (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/08/0c/9c3adb8f8a515201394c18d49daed795e61f03f9bcb24bbf09da6bbb704a/tenacity-4.4.0.tar.gz\n",
      "Collecting pytest>=3.3.1 (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/59/950a805f90587d6e2f3692cf43700becb7cdf6c16b06d84e7516b199236b/pytest-3.6.0-py2.py3-none-any.whl\n",
      "Collecting posix-ipc==1.0.4 (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/c9/3e/54217da71aa26b488295d878df4d3132093253b4ae5798ac66fcb6921ef0/posix_ipc-1.0.4.tar.gz\n",
      "Collecting google-auth>=1.0.2 (from cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/e0/18/e282ecb28c7eb0ef5ea9a69fb3290658a9ab37bb69647f6ba7f0f78987c4/google_auth-1.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from protobuf>=3.3.0->cloud-volume)\n",
      "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3>=1.4.7->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |################################| 61kB 2.0MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting botocore<1.11.0,>=1.10.28 (from boto3>=1.4.7->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/2e/91/f0870d4de8eb78897ce781f3ff22fc492bbb9849b5c91f26db20b125ef36/botocore-1.10.28-py2.py3-none-any.whl (4.2MB)\n",
      "\u001b[K    100% |################################| 4.2MB 368kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3>=1.4.7->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Collecting idna<2.7,>=2.5 (from requests>=2.18.4->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/27/cc/6dd9a3869f15c2edfab863b992838277279ce92663d334df9ecf5106f5c6/idna-2.6-py2.py3-none-any.whl (56kB)\n",
      "\u001b[K    100% |################################| 61kB 11.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests>=2.18.4->cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/7c/e6/92ad559b7192d846975fc916b65f667c7b8c3a32bea7372340bfe9a15fa5/certifi-2018.4.16-py2.py3-none-any.whl\n",
      "Collecting google-cloud-error-reporting<0.29dev,>=0.28.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/f3/4071bc943b48e70e41bfc56ed5ecbb5a7eddd8312f10c25a8834669ea20d/google_cloud_error_reporting-0.28.0-py2.py3-none-any.whl\n",
      "Collecting google-api-core<0.2.0dev,>=0.1.2 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/10/65/6237293db4fbf6f0bcf7c2b67c63e4dc4837c631f194064ae84957cd0313/google_api_core-0.1.4-py2.py3-none-any.whl (50kB)\n",
      "\u001b[K    100% |################################| 51kB 10.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-videointelligence<1.1dev,>=1.0.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/da/e4/57ffb1ef3fb003815789c684b3e7abd9f5df6f66471b08d5213bea6900d4/google_cloud_videointelligence-1.0.1-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |################################| 61kB 11.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-speech<0.31dev,>=0.30.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/70/a5/f4722af1873e59e84ee1f6d28eb44cb697174f6ee4433a1cc89bd76f9890/google_cloud_speech-0.30.0-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K    100% |################################| 51kB 12.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-dns<0.29dev,>=0.28.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/57/16/0098588f04399897209d4e854e430db4c8bb540ec84b9431ec30c320ac7a/google_cloud_dns-0.28.0-py2.py3-none-any.whl\n",
      "Collecting google-cloud-vision<0.30dev,>=0.29.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/db/56/49a9819835ef58b6547af22bb8d70677b24f3219eb47d35aa61428008474/google_cloud_vision-0.29.0-py2.py3-none-any.whl (71kB)\n",
      "\u001b[K    100% |################################| 81kB 11.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-runtimeconfig<0.29dev,>=0.28.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/df/fd/12949f877975e2583cd3cd192e73759a3ba5b4f59974a669eaecc6f375df/google_cloud_runtimeconfig-0.28.1-py2.py3-none-any.whl\n",
      "Collecting google-cloud-trace<0.18dev,>=0.17.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/44/261efe8430c05509d7cadcb1bdd87745afb7a2d999f5fa41b0ee92ee6637/google_cloud_trace-0.17.0-py2.py3-none-any.whl (68kB)\n",
      "\u001b[K    100% |################################| 71kB 7.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-monitoring<0.29dev,>=0.28.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/68/99/67195b899d8e1189807130062ba68018533677879590673028671fe4c570/google_cloud_monitoring-0.28.1-py2.py3-none-any.whl\n",
      "Collecting google-cloud-container<0.2dev,>=0.1.0 (from google-cloud==0.32.0->cloud-volume)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading https://files.pythonhosted.org/packages/fb/40/8e603a2acf6e1c81272f29cfaff2db60436545f8667b32853e58b160cb39/google_cloud_container-0.1.1-py2.py3-none-any.whl (50kB)\n",
      "\u001b[K    100% |################################| 51kB 9.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-logging<1.5dev,>=1.4.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/12/a6/c6f0fd13fbe70b007b105d42b1914e186dea60bc58628f694ae2b369d20b/google_cloud_logging-1.4.0-py2.py3-none-any.whl (43kB)\n",
      "\u001b[K    100% |################################| 51kB 11.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-pubsub<0.31dev,>=0.30.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/a2/4e0576083986296d21c530738530bd9de4dcb0fd4728e963ad8ff7e1620f/google_cloud_pubsub-0.30.1-py2.py3-none-any.whl (88kB)\n",
      "\u001b[K    100% |################################| 92kB 11.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-core<0.29dev,>=0.28.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/41/ae2418b4003a14cf21c1c46d61d1b044bf02cf0f8f91598af572b9216515/google_cloud_core-0.28.1-py2.py3-none-any.whl\n",
      "Collecting google-cloud-resource-manager<0.29dev,>=0.28.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/d6/bf/ed87e187c214154dd8a630c779dd103e9080026c9b046e9d0c52694f332c/google_cloud_resource_manager-0.28.1-py2.py3-none-any.whl\n",
      "Collecting google-cloud-translate<1.4dev,>=1.3.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/40/32/e17ba4b6586c31afe08a82fd0e3437906757a5fedb29e44d695721ffdbb8/google_cloud_translate-1.3.1-py2.py3-none-any.whl\n",
      "Collecting google-cloud-bigquery-datatransfer<0.2dev,>=0.1.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/12/6b/636a8702adad77b38f3df951be3c846dfcd8c79854ed2d71654be5602ab8/google_cloud_bigquery_datatransfer-0.1.1-py2.py3-none-any.whl\n",
      "Collecting google-cloud-bigquery<0.29dev,>=0.28.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/7c/f6/193729cb124770c710b9eab14f2fe2c3c7b285cc7b8cc70f48c162616e09/google_cloud_bigquery-0.28.0-py2.py3-none-any.whl (64kB)\n",
      "\u001b[K    100% |################################| 71kB 12.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-firestore<0.29dev,>=0.28.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/d3/3c/6f25b101d5c2584bfb6db74d75b9a08094a9986623acd372336f72ccd084/google_cloud_firestore-0.28.0-py2.py3-none-any.whl (150kB)\n",
      "\u001b[K    100% |################################| 153kB 7.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-datastore<1.5dev,>=1.4.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/aa/bc/2cee1ac9cc70764845a6ff73e4e5dc50aef1225aac417461e1ef878ed38e/google_cloud_datastore-1.4.0-py2.py3-none-any.whl (44kB)\n",
      "\u001b[K    100% |################################| 51kB 11.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-language<1.1dev,>=1.0.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/c8/f7/2fa4d0ea8381fccd182b4b9c408dae780c59bcfd60dde016b90a552f2cd2/google_cloud_language-1.0.2-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |################################| 61kB 11.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-storage<1.7dev,>=1.6.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/c8/13/131c4d6b72411bcd56ab82a70a256d961e8d87e7b6356c12791c0003765d/google_cloud_storage-1.6.0-py2.py3-none-any.whl (51kB)\n",
      "\u001b[K    100% |################################| 61kB 13.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-spanner<0.30dev,>=0.29.0 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/3f/d1771299f1df521dd918830511f03d1df9ee27d5a2e20252811feed39060/google_cloud_spanner-0.29.0-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K    100% |################################| 143kB 8.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-bigtable<0.29dev,>=0.28.1 (from google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/03/38/97d17a7fefc8596d49be95b409f9476d5c31bd9fb00d9c243652b883099f/google_cloud_bigtable-0.28.1-py2.py3-none-any.whl (88kB)\n",
      "\u001b[K    100% |################################| 92kB 9.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mock (from intern->cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl\n",
      "Collecting blosc==1.4.4 (from intern->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/19/cc48ff2219cd479ab4c867eebaf865b32cbe67d8607c1f7b02c3e749ca2f/blosc-1.4.4.tar.gz (613kB)\n",
      "\u001b[K    100% |################################| 614kB 2.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nose2 (from intern->cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/93/46/a389a65237d0520bb4a98fc174fdf6568ad9dcc79b9c1d1f30afc6776031/nose2-0.7.4.tar.gz\n",
      "Collecting Markdown==2.4 (from python-jsonschema-objects==0.2.1->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/5d/d259c3b20aaafade22b3fb220fcfeee03124562ace2c6ddba7a5474a76c5/Markdown-2.4.tar.gz (260kB)\n",
      "\u001b[K    100% |################################| 266kB 5.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jsonschema==2.3.0 (from python-jsonschema-objects==0.2.1->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/20/1c/52812523feebd744ac0e268224b5bae048b1559c88728f3628d169427947/jsonschema-2.3.0-py2.py3-none-any.whl\n",
      "Collecting pandocfilters==1.2 (from python-jsonschema-objects==0.2.1->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/18/ce/4c38a7e4f0eec5c071ff94d322f37f75af1f20b4c443d023c423219a2add/pandocfilters-1.2.tar.gz\n",
      "Collecting inflection==0.2.0 (from python-jsonschema-objects==0.2.1->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/17/17/e063022e2b77cb9f4a83ed4089e5b0debdddbc6b685c679f387b657c73c1/inflection-0.2.0.tar.gz\n",
      "Collecting monotonic>=0.6 (from tenacity==4.4.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n",
      "Collecting attrs>=17.4.0 (from pytest>=3.3.1->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/41/59/cedf87e91ed541be7957c501a92102f9cc6363c623a7666d69d51c78ac5b/attrs-18.1.0-py2.py3-none-any.whl\n",
      "Collecting more-itertools>=4.0.0 (from pytest>=3.3.1->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/85/40/90c3b0393e12b9827381004224de8814686e3d7182f9d4182477f600826d/more_itertools-4.2.0-py3-none-any.whl (45kB)\n",
      "\u001b[K    100% |################################| 51kB 12.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting py>=1.5.0 (from pytest>=3.3.1->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/67/a5/f77982214dd4c8fd104b066f249adea2c49e25e8703d284382eb5e9ab35a/py-1.5.3-py2.py3-none-any.whl (84kB)\n",
      "\u001b[K    100% |################################| 92kB 11.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting atomicwrites>=1.0 (from pytest>=3.3.1->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/0a/e8/cd6375e7a59664eeea9e1c77a766eeac0fc3083bb958c2b41ec46b95f29c/atomicwrites-1.1.5-py2.py3-none-any.whl\n",
      "Collecting pluggy<0.7,>=0.5 (from pytest>=3.3.1->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/ba/65/ded3bc40bbf8d887f262f150fbe1ae6637765b5c9534bd55690ed2c0b0f7/pluggy-0.6.0-py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.2->cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/51/bcd96bf6231d4b2cc5e023c511bee86637ba375c44a6f9d1b4b7ad1ce4b9/pyasn1_modules-0.2.1-py2.py3-none-any.whl\n",
      "Collecting cachetools>=2.0.0 (from google-auth>=1.0.2->cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/0a/58/cbee863250b31d80f47401d04f34038db6766f95dea1cc909ea099c7e571/cachetools-2.1.0-py2.py3-none-any.whl\n",
      "Collecting rsa>=3.1.4 (from google-auth>=1.0.2->cloud-volume)\n",
      "  Using cached https://files.pythonhosted.org/packages/e1/ae/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e/rsa-3.4.2-py2.py3-none-any.whl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docutils>=0.10 (from botocore<1.11.0,>=1.10.28->boto3>=1.4.7->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
      "\u001b[K    100% |################################| 552kB 2.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.5/dist-packages (from botocore<1.11.0,>=1.10.28->boto3>=1.4.7->cloud-volume)\n",
      "Collecting gapic-google-cloud-error-reporting-v1beta1<0.16dev,>=0.15.0 (from google-cloud-error-reporting<0.29dev,>=0.28.0->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/03/fb/903f4cb88a442e05ec789329aef76da0d3f841a66909e9b5bc39527e0ef7/gapic-google-cloud-error-reporting-v1beta1-0.15.3.tar.gz\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.5.3 (from google-api-core<0.2.0dev,>=0.1.2->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/00/03/d25bed04ec8d930bcfa488ba81a2ecbf7eb36ae3ffd7e8f5be0d036a89c9/googleapis-common-protos-1.5.3.tar.gz\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.5/dist-packages (from google-api-core<0.2.0dev,>=0.1.2->google-cloud==0.32.0->cloud-volume)\n",
      "Collecting google-gax<0.16dev,>=0.15.14 (from google-cloud-speech<0.31dev,>=0.30.0->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/b4/ff312fa42f91535c67567c1d08e972db0e7c548e9a63c6f3bcc5213b32fc/google_gax-0.15.16-py2.py3-none-any.whl (46kB)\n",
      "\u001b[K    100% |################################| 51kB 11.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting gapic-google-cloud-logging-v2<0.92dev,>=0.91.0 (from google-cloud-logging<1.5dev,>=1.4.0->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/aa/a8/2fcb30c255243d0b5b1a1c4b3cd0a73ca87c82f8a6673be60fb003a6e184/gapic-google-cloud-logging-v2-0.91.3.tar.gz\n",
      "Collecting grpc-google-iam-v1<0.12dev,>=0.11.1 (from google-cloud-pubsub<0.31dev,>=0.30.0->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/28/f26f67381cb23e81271b8d66c00a846ad9d25a909ae1ae1df8222fad2744/grpc-google-iam-v1-0.11.4.tar.gz\n",
      "Collecting google-resumable-media>=0.2.1 (from google-cloud-bigquery<0.29dev,>=0.28.0->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/77/95/2e4020a54366423ddba715f89fb7ca456c8f048b15cada6cd6a54cf10e8c/google_resumable_media-0.3.1-py2.py3-none-any.whl\n",
      "Collecting gapic-google-cloud-datastore-v1<0.16dev,>=0.15.0 (from google-cloud-datastore<1.5dev,>=1.4.0->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/ec/9c/6d69a6e6551006c4e87192a396b983421a6978bc57657619bc998a264b31/gapic-google-cloud-datastore-v1-0.15.3.tar.gz\n",
      "Collecting pbr>=0.11 (from mock->intern->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/2d/9d/7bfab757977067556c7ca5fe437f28e8b8843c95564fca504de79df63b25/pbr-4.0.3-py2.py3-none-any.whl (98kB)\n",
      "\u001b[K    100% |################################| 102kB 7.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting coverage>=4.4.1 (from nose2->intern->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/2c/c0/8047b7cbbcdbd7d21f8d68126196b7915da892c5af3d1a99dba082d33ec0/coverage-4.5.1-cp35-cp35m-manylinux1_x86_64.whl (202kB)\n",
      "\u001b[K    100% |################################| 204kB 6.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1<0.5.0,>=0.4.1 (from pyasn1-modules>=0.2.1->google-auth>=1.0.2->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/70/2c27740f08e477499ce19eefe05dbcae6f19fdc49e9e82ce4768be0643b9/pyasn1-0.4.3-py2.py3-none-any.whl (72kB)\n",
      "\u001b[K    100% |################################| 81kB 12.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting oauth2client<4.0dev,>=2.0.0 (from gapic-google-cloud-error-reporting-v1beta1<0.16dev,>=0.15.0->google-cloud-error-reporting<0.29dev,>=0.28.0->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/7b/bc893e35d6ca46a72faa4b9eaac25c687ce60e1fbe978993fe2de1b0ff0d/oauth2client-3.0.0.tar.gz (77kB)\n",
      "\u001b[K    100% |################################| 81kB 12.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting proto-google-cloud-error-reporting-v1beta1[grpc]<0.16dev,>=0.15.3 (from gapic-google-cloud-error-reporting-v1beta1<0.16dev,>=0.15.0->google-cloud-error-reporting<0.29dev,>=0.28.0->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/a1/94790efc86414a127fdf2c1277530c789b458bdd4b120630d4d84ea04898/proto-google-cloud-error-reporting-v1beta1-0.15.3.tar.gz\n",
      "Collecting ply==3.8 (from google-gax<0.16dev,>=0.15.14->google-cloud-speech<0.31dev,>=0.30.0->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/96/e0/430fcdb6b3ef1ae534d231397bee7e9304be14a47a267e82ebcb3323d0b5/ply-3.8.tar.gz (157kB)\n",
      "\u001b[K    100% |################################| 163kB 7.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.3dev,>=0.2.5 (from google-gax<0.16dev,>=0.15.14->google-cloud-speech<0.31dev,>=0.30.0->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/91/a0/19d4d31dee064fc553ae01263b5c55e7fb93daff03a69debbedee647c5a0/dill-0.2.7.1.tar.gz (64kB)\n",
      "\u001b[K    100% |################################| 71kB 11.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting future<0.17dev,>=0.16.0 (from google-gax<0.16dev,>=0.15.14->google-cloud-speech<0.31dev,>=0.30.0->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/00/2b/8d082ddfed935f3608cc61140df6dcbf0edea1bc3ab52fb6c29ae3e81e85/future-0.16.0.tar.gz (824kB)\n",
      "\u001b[K    100% |################################| 829kB 1.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0dev,>=1.0.2 (from google-gax<0.16dev,>=0.15.14->google-cloud-speech<0.31dev,>=0.30.0->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/2c/ff/f118147fd7a8d2d441d15e1cb7fefb2c1981586e24ef3a7d8a742535b085/grpcio-1.12.0-cp35-cp35m-manylinux1_x86_64.whl (9.0MB)\n",
      "\u001b[K    100% |################################| 9.0MB 174kB/s eta 0:00:01    85% |###########################     | 7.7MB 61.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting proto-google-cloud-logging-v2[grpc]<0.92dev,>=0.91.3 (from gapic-google-cloud-logging-v2<0.92dev,>=0.91.0->google-cloud-logging<1.5dev,>=1.4.0->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/36/cc/52c1b363b992546d4658a61eb551c85af94ad424734e6c899fdfc8330811/proto-google-cloud-logging-v2-0.91.3.tar.gz\n",
      "Collecting proto-google-cloud-datastore-v1[grpc]<0.91dev,>=0.90.3 (from gapic-google-cloud-datastore-v1<0.16dev,>=0.15.0->google-cloud-datastore<1.5dev,>=1.4.0->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/2a/1f/4124f15e1132a2eeeaf616d825990bb1d395b4c2c37362654ea5cd89bb42/proto-google-cloud-datastore-v1-0.90.4.tar.gz\n",
      "Collecting httplib2>=0.9.1 (from oauth2client<4.0dev,>=2.0.0->gapic-google-cloud-error-reporting-v1beta1<0.16dev,>=0.15.0->google-cloud-error-reporting<0.29dev,>=0.28.0->google-cloud==0.32.0->cloud-volume)\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/ce/aa4a385e3e9fd351737fd2b07edaa56e7a730448465aceda6b35086a0d9b/httplib2-0.11.3.tar.gz (215kB)\n",
      "\u001b[K    100% |################################| 225kB 6.6MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: psutil, tenacity, posix-ipc, blosc, nose2, Markdown, pandocfilters, inflection, gapic-google-cloud-error-reporting-v1beta1, googleapis-common-protos, gapic-google-cloud-logging-v2, grpc-google-iam-v1, gapic-google-cloud-datastore-v1, oauth2client, proto-google-cloud-error-reporting-v1beta1, ply, dill, future, proto-google-cloud-logging-v2, proto-google-cloud-datastore-v1, httplib2\n",
      "  Running setup.py bdist_wheel for psutil ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fe/33/84/baea3d665de2d1af7e8f827f3883811bba5e4149443ccf8191\n",
      "  Running setup.py bdist_wheel for tenacity ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/cf/dd/89/99693d2e2c5954ccd7b7ba4fe9571b385712939d25e584a03a\n",
      "  Running setup.py bdist_wheel for posix-ipc ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/5a/5c/17/d0e2d421abaf3b4097bf9db11108380d734195c6d15c24269d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running setup.py bdist_wheel for blosc ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fa/2a/00/8ff3a1d3d423a3163b93917a72146e85c3a3484ba6574854a5\n",
      "  Running setup.py bdist_wheel for nose2 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/66/65/52/e7e6215ebee79eff0f3a60db0e6e6f6d751c3ebbb7a52cdfbd\n",
      "  Running setup.py bdist_wheel for Markdown ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/34/2d/c2/75f4fd57c1b79e59f66388262ed37b69ceac77162988f8af63\n",
      "  Running setup.py bdist_wheel for pandocfilters ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fc/a0/4c/ec26eaa3f2253144e29941bd4031c317a69595dd0b665a0779\n",
      "  Running setup.py bdist_wheel for inflection ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9f/fa/4f/ef45a51543bd855e40494298824ad5e750109ad18fa80278ad\n",
      "  Running setup.py bdist_wheel for gapic-google-cloud-error-reporting-v1beta1 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/19/d9/9e/5d0f178712d65c20ef2e2573b4390f94864819fe0b29d91c8f\n",
      "  Running setup.py bdist_wheel for googleapis-common-protos ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/62/45/af/649bbf07b6595fda010be1bda667cd56d0444d07afc6f8b687\n",
      "  Running setup.py bdist_wheel for gapic-google-cloud-logging-v2 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/67/f7/2c/c104c937201a0a2bba168ae7058ce7d10da96d881b504a1ae4\n",
      "  Running setup.py bdist_wheel for grpc-google-iam-v1 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b6/c6/31/c20321a5a3fde456fc375b7c2814135e6e98bc0d74c40239d9\n",
      "  Running setup.py bdist_wheel for gapic-google-cloud-datastore-v1 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/79/a9/0f/1b6929a5f1961d22553efa844ea60c589bffcf6e1bd019f7c9\n",
      "  Running setup.py bdist_wheel for oauth2client ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/48/f7/87/b932f09c6335dbcf45d916937105a372ab14f353a9ca431d7d\n",
      "  Running setup.py bdist_wheel for proto-google-cloud-error-reporting-v1beta1 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/76/fc/f8/49959a924b1e0d76264f251ea9ab9d27e6b978acf02cd28bff\n",
      "  Running setup.py bdist_wheel for ply ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f2/21/c0/f0056cc96847933daa961a19eb59a2ecd0228fdbe3376e7a68\n",
      "  Running setup.py bdist_wheel for dill ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/99/c4/ed/1b64d2d5809e60d5a3685530432f6159d6a9959739facb61f2\n",
      "  Running setup.py bdist_wheel for future ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/bf/c9/a3/c538d90ef17cf7823fa51fc701a7a7a910a80f6a405bf15b1a\n",
      "  Running setup.py bdist_wheel for proto-google-cloud-logging-v2 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a2/63/53/2c822aa22c24d620ce09f799ff1b38cceaac1ae7698368b0d8\n",
      "  Running setup.py bdist_wheel for proto-google-cloud-datastore-v1 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/bd/ce/33/8b769968db3761c42c7a91d8a0dbbafc50acfa0750866c8abd\n",
      "  Running setup.py bdist_wheel for httplib2 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/1b/9c/9e/1f6fdb21dbb1fe6a99101d697f12cb8c1fa96c1587df69adba\n",
      "Successfully built psutil tenacity posix-ipc blosc nose2 Markdown pandocfilters inflection gapic-google-cloud-error-reporting-v1beta1 googleapis-common-protos gapic-google-cloud-logging-v2 grpc-google-iam-v1 gapic-google-cloud-datastore-v1 oauth2client proto-google-cloud-error-reporting-v1beta1 ply dill future proto-google-cloud-logging-v2 proto-google-cloud-datastore-v1 httplib2\n",
      "Installing collected packages: tqdm, six, protobuf, docutils, jmespath, botocore, s3transfer, boto3, json5, idna, certifi, urllib3, chardet, requests, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, googleapis-common-protos, google-api-core, google-cloud-core, ply, dill, future, grpcio, google-gax, httplib2, oauth2client, proto-google-cloud-logging-v2, gapic-google-cloud-logging-v2, google-cloud-logging, proto-google-cloud-error-reporting-v1beta1, gapic-google-cloud-error-reporting-v1beta1, google-cloud-error-reporting, google-cloud-videointelligence, google-cloud-speech, google-cloud-dns, google-cloud-vision, google-cloud-runtimeconfig, google-cloud-trace, google-cloud-monitoring, google-cloud-container, grpc-google-iam-v1, psutil, google-cloud-pubsub, google-cloud-resource-manager, google-cloud-translate, google-cloud-bigquery-datatransfer, google-resumable-media, google-cloud-bigquery, google-cloud-firestore, proto-google-cloud-datastore-v1, gapic-google-cloud-datastore-v1, google-cloud-datastore, google-cloud-language, google-cloud-storage, google-cloud-spanner, google-cloud-bigtable, google-cloud, pbr, mock, blosc, coverage, nose2, intern, backports-abc, Markdown, jsonschema, pandocfilters, inflection, python-jsonschema-objects, monotonic, tenacity, attrs, more-itertools, py, atomicwrites, pluggy, pytest, posix-ipc, cloud-volume\n",
      "  Found existing installation: six 1.11.0\n",
      "    Uninstalling six-1.11.0:\n",
      "      Successfully uninstalled six-1.11.0\n",
      "  Found existing installation: jsonschema 2.6.0\n",
      "    Uninstalling jsonschema-2.6.0:\n",
      "      Successfully uninstalled jsonschema-2.6.0\n",
      "  Found existing installation: pandocfilters 1.4.2\n",
      "    Uninstalling pandocfilters-1.4.2:\n",
      "      Successfully uninstalled pandocfilters-1.4.2\n",
      "Successfully installed Markdown-2.4 atomicwrites-1.1.5 attrs-18.1.0 backports-abc-0.5 blosc-1.4.4 boto3-1.7.28 botocore-1.10.28 cachetools-2.1.0 certifi-2018.4.16 chardet-3.0.4 cloud-volume-0.23.0 coverage-4.5.1 dill-0.2.7.1 docutils-0.14 future-0.16.0 gapic-google-cloud-datastore-v1-0.15.3 gapic-google-cloud-error-reporting-v1beta1-0.15.3 gapic-google-cloud-logging-v2-0.91.3 google-api-core-0.1.4 google-auth-1.4.1 google-cloud-0.32.0 google-cloud-bigquery-0.28.0 google-cloud-bigquery-datatransfer-0.1.1 google-cloud-bigtable-0.28.1 google-cloud-container-0.1.1 google-cloud-core-0.28.1 google-cloud-datastore-1.4.0 google-cloud-dns-0.28.0 google-cloud-error-reporting-0.28.0 google-cloud-firestore-0.28.0 google-cloud-language-1.0.2 google-cloud-logging-1.4.0 google-cloud-monitoring-0.28.1 google-cloud-pubsub-0.30.1 google-cloud-resource-manager-0.28.1 google-cloud-runtimeconfig-0.28.1 google-cloud-spanner-0.29.0 google-cloud-speech-0.30.0 google-cloud-storage-1.6.0 google-cloud-trace-0.17.0 google-cloud-translate-1.3.1 google-cloud-videointelligence-1.0.1 google-cloud-vision-0.29.0 google-gax-0.15.16 google-resumable-media-0.3.1 googleapis-common-protos-1.5.3 grpc-google-iam-v1-0.11.4 grpcio-1.12.0 httplib2-0.11.3 idna-2.6 inflection-0.2.0 intern-0.9.6 jmespath-0.9.3 json5-0.5.1 jsonschema-2.3.0 mock-2.0.0 monotonic-1.5 more-itertools-4.2.0 nose2-0.7.4 oauth2client-3.0.0 pandocfilters-1.2 pbr-4.0.3 pluggy-0.6.0 ply-3.8 posix-ipc-1.0.4 proto-google-cloud-datastore-v1-0.90.4 proto-google-cloud-error-reporting-v1beta1-0.15.3 proto-google-cloud-logging-v2-0.91.3 protobuf-3.5.2.post1 psutil-5.4.3 py-1.5.3 pyasn1-0.4.3 pyasn1-modules-0.2.1 pytest-3.6.0 python-jsonschema-objects-0.2.1 requests-2.18.4 rsa-3.4.2 s3transfer-0.1.13 six-1.10.0 tenacity-4.4.0 tqdm-4.23.4 urllib3-1.22\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.5/dist-packages (from scikit-image)\n",
      "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.5/dist-packages (from scikit-image)\n",
      "Requirement already satisfied: six>=1.7.3 in /usr/local/lib/python3.5/dist-packages (from scikit-image)\n",
      "Requirement already satisfied: pillow>=2.1.0 in /usr/local/lib/python3.5/dist-packages (from scikit-image)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.5/dist-packages (from scikit-image)\n",
      "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.5/dist-packages (from scikit-image)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.5/dist-packages (from scipy>=0.17.0->scikit-image)\n",
      "Requirement already satisfied: decorator>=4.1.0 in /usr/local/lib/python3.5/dist-packages (from networkx>=1.8->scikit-image)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.3.1->scikit-image)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/.cloudvolume/secrets\n",
    "!cp /notebooks/*.json ~/.cloudvolume/secrets/\n",
    "!pip install cloud-volume\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudvolume import CloudVolume\n",
    "from cloudvolume.lib import Bbox, Vec\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from optimize import Optimizer\n",
    "from copy import deepcopy\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bbox([25679, 26769, 526],[26191, 27281, 527])\n",
      "Bbox([25679, 26769, 527],[26191, 27281, 528])\n",
      "Bbox([3209, 3346, 526],[3273, 3410, 527])\n"
     ]
    }
   ],
   "source": [
    "def use_src_mask_and_one_dst():\n",
    "    img_mip = 2\n",
    "    mask_mip = 5\n",
    "    src = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/unmasked\", mip=img_mip, \n",
    "                                                                    parallel=2, fill_missing=True)\n",
    "    cracks = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/crack_detector_v3\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)\n",
    "    folds = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/fold_detector_v1\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)\n",
    "    flow = Optimizer(ndownsamples=5, currn=5, avgn=20, lambda1=0.5, lr=0.1, eps=0.001, min_iter=100, max_iter=5000)\n",
    "    full_offset = np.array([102716, 107077, 526])\n",
    "    full_size = np.array([2048, 2048, 1])\n",
    "    full_bbox = Bbox(full_offset, full_offset+full_size)\n",
    "    src_bbox = Bbox.from_slices(src.slices_from_global_coords(full_bbox))\n",
    "    dst_bbox = src_bbox + [0,0,1]\n",
    "    mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_bbox))\n",
    "    print(src_bbox)\n",
    "    print(dst_bbox)\n",
    "    print(mask_bbox)\n",
    "    dst = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/optimizer_tests/v01_with_mask\", mip=img_mip, \n",
    "                        info=src.info, parallel=False, fill_missing=True, non_aligned_writes=True, cdn_cache=False)\n",
    "    dst.commit_info();\n",
    "    dst[dst_bbox.to_slices()] = src[dst_bbox.to_slices()]\n",
    "    src_img = src[src_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    dst_img = src[dst_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "\n",
    "    fold = folds[mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    crack = cracks[mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    mask = resize(np.minimum(fold, crack), src_bbox.size3()[:2])\n",
    "    field = flow.process(src_img, [dst_img], mask, [np.ones_like(dst_img)])\n",
    "    pred = flow.render(src_img, field)\n",
    "    dst[src_bbox.to_slices()] = (pred[0,0,:,:,np.newaxis, np.newaxis]*255).astype(np.uint8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_masks_and_two_dsts():\n",
    "    img_mip = 2\n",
    "    mask_mip = 5\n",
    "    src = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/unmasked\", mip=img_mip, \n",
    "                                                                    parallel=2, fill_missing=True)\n",
    "    cracks = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/crack_detector_v3\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)\n",
    "    folds = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/fold_detector_v1\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)    \n",
    "    flow = Optimizer(ndownsamples=5, currn=5, avgn=20, lambda1=0.5, lr=0.1, eps=0.001, min_iter=100, max_iter=5000)\n",
    "    full_src_offset = np.array([102716, 107077, 526])\n",
    "    full_src_size = np.array([2048, 2048, 1])\n",
    "    full_src_bbox = Bbox(full_src_offset, full_src_offset+full_src_size)\n",
    "    src_bbox = Bbox.from_slices(src.slices_from_global_coords(full_src_bbox))\n",
    "    src_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_src_bbox))\n",
    "    dst_bboxes = []\n",
    "    dst_mask_bboxes = []\n",
    "    for z in [-1,1]:\n",
    "        full_dst_bbox = full_bbox + [0,0,z]\n",
    "        dst_bbox = Bbox.from_slices(src.slices_from_global_coords(full_dst_bbox))\n",
    "        dst_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_dst_bbox))\n",
    "        dst_bboxes.append(dst_bbox)\n",
    "        dst_mask_bboxes.append(dst_mask_bbox)\n",
    "        \n",
    "    dst = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/optimizer_tests/v01_mask_two_dsts\", \n",
    "          mip=img_mip, info=src.info, parallel=False, fill_missing=True, non_aligned_writes=True, cdn_cache=False)\n",
    "    dst.commit_info();\n",
    "    \n",
    "    dst_images = []\n",
    "    dst_masks = []\n",
    "    for dst_bbox, dst_mask_bbox in zip(dst_bboxes, dst_mask_bboxes):\n",
    "        dst_slices = dst_bbox.to_slices()\n",
    "        mask_slices = dst_mask_bbox.to_slices()\n",
    "        dst[dst_slices] = src[dst_slices]\n",
    "        \n",
    "        dst_images.append(src[dst_slices][:,:,0,0] / 255.0)\n",
    "        dst_fold = folds[mask_slices][:,:,0,0] / 255.0\n",
    "        dst_crack = cracks[mask_slices][:,:,0,0] / 255.0\n",
    "        dst_mask = resize(np.minimum(dst_fold, dst_crack), dst_bbox.size3()[:2])\n",
    "        dst_masks.append(dst_mask)\n",
    "        \n",
    "        \n",
    "    src_image = src[src_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_fold = folds[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_crack = cracks[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_mask = resize(np.minimum(src_fold, src_crack), src_bbox.size3()[:2])\n",
    "    \n",
    "    field = flow.process(src_image, dst_images, src_mask, dst_masks)\n",
    "    pred = flow.render(src_image, field)\n",
    "    dst[src_bbox.to_slices()] = (pred[0,0,:,:,np.newaxis, np.newaxis]*255).astype(np.uint8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_masks_and_four_dsts():\n",
    "    img_mip = 2\n",
    "    mask_mip = 5\n",
    "    src = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/unmasked\", mip=img_mip, \n",
    "                                                                    parallel=2, fill_missing=True)\n",
    "    cracks = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/crack_detector_v3\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)\n",
    "    folds = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/fold_detector_v1\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)    \n",
    "    flow = Optimizer(ndownsamples=5, currn=5, avgn=20, lambda1=0.5, lr=0.1, eps=0.001, min_iter=100, max_iter=5000)\n",
    "    full_src_offset = np.array([102716, 107077, 526])\n",
    "    full_src_size = np.array([2048, 2048, 1])\n",
    "    full_src_bbox = Bbox(full_src_offset, full_src_offset+full_src_size)\n",
    "    src_bbox = Bbox.from_slices(src.slices_from_global_coords(full_src_bbox))\n",
    "    src_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_src_bbox))\n",
    "    dst_bboxes = []\n",
    "    dst_mask_bboxes = []\n",
    "    for z in [-2,-1,1,2]:\n",
    "        full_dst_bbox = full_bbox + [0,0,z]\n",
    "        dst_bbox = Bbox.from_slices(src.slices_from_global_coords(full_dst_bbox))\n",
    "        dst_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_dst_bbox))\n",
    "        dst_bboxes.append(dst_bbox)\n",
    "        dst_mask_bboxes.append(dst_mask_bbox)\n",
    "        \n",
    "    dst = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/optimizer_tests/v01_mask_four_dsts\", \n",
    "          mip=img_mip, info=src.info, parallel=False, fill_missing=True, non_aligned_writes=True, cdn_cache=False)\n",
    "    dst.commit_info();\n",
    "    \n",
    "    dst_images = []\n",
    "    dst_masks = []\n",
    "    for dst_bbox, dst_mask_bbox in zip(dst_bboxes, dst_mask_bboxes):\n",
    "        dst_slices = dst_bbox.to_slices()\n",
    "        mask_slices = dst_mask_bbox.to_slices()\n",
    "        dst[dst_slices] = src[dst_slices]\n",
    "        \n",
    "        dst_images.append(src[dst_slices][:,:,0,0] / 255.0)\n",
    "        dst_fold = folds[mask_slices][:,:,0,0] / 255.0\n",
    "        dst_crack = cracks[mask_slices][:,:,0,0] / 255.0\n",
    "        dst_mask = resize(np.minimum(dst_fold, dst_crack), dst_bbox.size3()[:2])\n",
    "        dst_masks.append(dst_mask)\n",
    "        \n",
    "        \n",
    "    src_image = src[src_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_fold = folds[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_crack = cracks[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_mask = resize(np.minimum(src_fold, src_crack), src_bbox.size3()[:2])\n",
    "    \n",
    "    field = flow.process(src_image, dst_images, src_mask, dst_masks)\n",
    "    pred = flow.render(src_image, field)\n",
    "    dst[src_bbox.to_slices()] = (pred[0,0,:,:,np.newaxis, np.newaxis]*255).astype(np.uint8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_filtered_mask_and_two_dsts():\n",
    "    img_mip = 2\n",
    "    mask_mip = 5\n",
    "    src = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/unmasked\", mip=img_mip, \n",
    "                                                                    parallel=2, fill_missing=True)\n",
    "    cracks = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/crack_detector_v3\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)\n",
    "    folds = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/fold_detector_v1\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)    \n",
    "    flow = Optimizer(ndownsamples=5, currn=5, avgn=20, lambda1=0.5, lr=0.1, eps=0.001, min_iter=100, max_iter=5000)\n",
    "    full_src_offset = np.array([102716, 107077, 526])\n",
    "    full_src_size = np.array([2048, 2048, 1])\n",
    "    full_src_bbox = Bbox(full_src_offset, full_src_offset+full_src_size)\n",
    "    src_bbox = Bbox.from_slices(src.slices_from_global_coords(full_src_bbox))\n",
    "    src_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_src_bbox))\n",
    "    dst_bboxes = []\n",
    "    dst_mask_bboxes = []\n",
    "    for z in [-1,1]:\n",
    "        full_dst_bbox = full_bbox + [0,0,z]\n",
    "        dst_bbox = Bbox.from_slices(src.slices_from_global_coords(full_dst_bbox))\n",
    "        dst_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_dst_bbox))\n",
    "        dst_bboxes.append(dst_bbox)\n",
    "        dst_mask_bboxes.append(dst_mask_bbox)\n",
    "        \n",
    "    dst = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/optimizer_tests/v01_filtered_mask_two_dsts\", \n",
    "          mip=img_mip, info=src.info, parallel=False, fill_missing=True, non_aligned_writes=True, cdn_cache=False)\n",
    "    dst.commit_info();\n",
    "    \n",
    "    dst_images = []\n",
    "    dst_masks = []\n",
    "    for dst_bbox, dst_mask_bbox in zip(dst_bboxes, dst_mask_bboxes):\n",
    "        dst_slices = dst_bbox.to_slices()\n",
    "        mask_slices = dst_mask_bbox.to_slices()\n",
    "        dst[dst_slices] = src[dst_slices]\n",
    "        \n",
    "        dst_images.append(src[dst_slices][:,:,0,0] / 255.0)\n",
    "        dst_fold = folds[mask_slices][:,:,0,0] / 255.0\n",
    "        dst_crack = cracks[mask_slices][:,:,0,0] / 255.0\n",
    "        dst_mask = resize(np.minimum(dst_fold, dst_crack), dst_bbox.size3()[:2])\n",
    "        dst_masks.append(dst_mask)\n",
    "        \n",
    "        \n",
    "    src_image = src[src_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_fold = folds[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_crack = cracks[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_mask = resize(np.minimum(src_fold, src_crack), src_bbox.size3()[:2])\n",
    "    \n",
    "    src_mask *= (src_mask < 1/255.0) | (src_mask > 10/255.0)\n",
    "    \n",
    "    field = flow.process(src_image, dst_images, src_mask, dst_masks)\n",
    "    pred = flow.render(src_image, field)\n",
    "    dst[src_bbox.to_slices()] = (pred[0,0,:,:,np.newaxis, np.newaxis]*255).astype(np.uint8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_filtered_mask_and_two_dsts2():\n",
    "    img_mip = 2\n",
    "    mask_mip = 5\n",
    "    src = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/unmasked\", mip=img_mip, \n",
    "                                                                    parallel=2, fill_missing=True)\n",
    "    cracks = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/crack_detector_v3\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)\n",
    "    folds = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/fold_detector_v1\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)    \n",
    "    flow = Optimizer(ndownsamples=5, currn=5, avgn=20, lambda1=0.5, lr=0.1, eps=0.001, min_iter=100, max_iter=5000)\n",
    "    full_src_offset = np.array([102716, 107077, 526])\n",
    "    full_src_size = np.array([2048, 2048, 1])\n",
    "    full_src_bbox = Bbox(full_src_offset, full_src_offset+full_src_size)\n",
    "    src_bbox = Bbox.from_slices(src.slices_from_global_coords(full_src_bbox))\n",
    "    src_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_src_bbox))\n",
    "    dst_bboxes = []\n",
    "    dst_mask_bboxes = []\n",
    "    for z in [-1,1]:\n",
    "        full_dst_bbox = full_bbox + [0,0,z]\n",
    "        dst_bbox = Bbox.from_slices(src.slices_from_global_coords(full_dst_bbox))\n",
    "        dst_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_dst_bbox))\n",
    "        dst_bboxes.append(dst_bbox)\n",
    "        dst_mask_bboxes.append(dst_mask_bbox)\n",
    "        \n",
    "    dst = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/optimizer_tests/v01_filtered_mask_two_dsts2\", \n",
    "          mip=img_mip, info=src.info, parallel=False, fill_missing=True, non_aligned_writes=True, cdn_cache=False)\n",
    "    dst.commit_info();\n",
    "    \n",
    "    dst_images = []\n",
    "    dst_masks = []\n",
    "    for dst_bbox, dst_mask_bbox in zip(dst_bboxes, dst_mask_bboxes):\n",
    "        dst_slices = dst_bbox.to_slices()\n",
    "        mask_slices = dst_mask_bbox.to_slices()\n",
    "        dst[dst_slices] = src[dst_slices]\n",
    "        \n",
    "        dst_images.append(src[dst_slices][:,:,0,0] / 255.0)\n",
    "        dst_fold = folds[mask_slices][:,:,0,0] / 255.0\n",
    "        dst_crack = cracks[mask_slices][:,:,0,0] / 255.0\n",
    "        dst_mask = resize(np.minimum(dst_fold, dst_crack), dst_bbox.size3()[:2])\n",
    "        dst_masks.append(dst_mask)\n",
    "        \n",
    "        \n",
    "    src_image = src[src_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_fold = folds[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_crack = cracks[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_mask = resize(np.minimum(src_fold, src_crack), src_bbox.size3()[:2])\n",
    "    \n",
    "    src_mask *= (src_mask < 4/255.0) | (src_mask > 10/255.0)\n",
    "    \n",
    "    field = flow.process(src_image, dst_images, src_mask, dst_masks)\n",
    "    pred = flow.render(src_image, field)\n",
    "    dst[src_bbox.to_slices()] = (pred[0,0,:,:,np.newaxis, np.newaxis]*255).astype(np.uint8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_masks_and_two_dsts_mip1():\n",
    "    img_mip = 1\n",
    "    mask_mip = 5\n",
    "    src = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/unmasked\", mip=img_mip, \n",
    "                                                                    parallel=2, fill_missing=True)\n",
    "    cracks = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/crack_detector_v3\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)\n",
    "    folds = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/fold_detector_v1\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)\n",
    "    flow = Optimizer(ndownsamples=5, currn=5, avgn=20, lambda1=0.5, lr=0.1, eps=0.001, min_iter=100, max_iter=5000)\n",
    "    full_src_offset = np.array([102716, 107077, 526])\n",
    "    full_src_size = np.array([2048, 2048, 1])\n",
    "    full_src_bbox = Bbox(full_src_offset, full_src_offset+full_src_size)\n",
    "    src_bbox = Bbox.from_slices(src.slices_from_global_coords(full_src_bbox))\n",
    "    src_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_src_bbox))\n",
    "    dst_bboxes = []\n",
    "    dst_mask_bboxes = []\n",
    "    for z in [-1,1]:\n",
    "        full_dst_bbox = full_src_bbox + [0,0,z]\n",
    "        dst_bbox = Bbox.from_slices(src.slices_from_global_coords(full_dst_bbox))\n",
    "        dst_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_dst_bbox))\n",
    "        dst_bboxes.append(dst_bbox)\n",
    "        dst_mask_bboxes.append(dst_mask_bbox)\n",
    "        \n",
    "    dst = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/optimizer_tests/v01_mask_two_dsts_mip1\", \n",
    "          mip=img_mip, info=src.info, parallel=False, fill_missing=True, non_aligned_writes=True, cdn_cache=False)\n",
    "    dst.commit_info();\n",
    "    \n",
    "    dst_images = []\n",
    "    dst_masks = []\n",
    "    for dst_bbox, dst_mask_bbox in zip(dst_bboxes, dst_mask_bboxes):\n",
    "        dst_slices = dst_bbox.to_slices()\n",
    "        mask_slices = dst_mask_bbox.to_slices()\n",
    "        dst[dst_slices] = src[dst_slices]\n",
    "        \n",
    "        dst_images.append(src[dst_slices][:,:,0,0] / 255.0)\n",
    "        dst_fold = folds[mask_slices][:,:,0,0] / 255.0\n",
    "        dst_crack = cracks[mask_slices][:,:,0,0] / 255.0\n",
    "        dst_mask = resize(np.minimum(dst_fold, dst_crack), dst_bbox.size3()[:2])\n",
    "        dst_masks.append(dst_mask)\n",
    "        \n",
    "        \n",
    "    src_image = src[src_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_fold = folds[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_crack = cracks[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_mask = resize(np.minimum(src_fold, src_crack), src_bbox.size3()[:2])\n",
    "    \n",
    "    field = flow.process(src_image, dst_images, src_mask, dst_masks)\n",
    "    pred = flow.render(src_image, field)\n",
    "    dst[src_bbox.to_slices()] = (pred[0,0,:,:,np.newaxis, np.newaxis]*255).astype(np.uint8)\n",
    "    return field\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_masks_and_two_dsts_mip0():\n",
    "    img_mip = 0\n",
    "    mask_mip = 5\n",
    "    src = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/unmasked\", mip=img_mip, \n",
    "                                                                    parallel=2, fill_missing=True)\n",
    "    cracks = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/crack_detector_v3\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)\n",
    "    folds = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/fold_detector_v1\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)\n",
    "    flow = Optimizer(ndownsamples=5, currn=5, avgn=20, lambda1=0.5, lr=0.1, eps=0.001, min_iter=100, max_iter=5000)\n",
    "    full_src_offset = np.array([102716, 107077, 526])\n",
    "    full_src_size = np.array([2048, 2048, 1])\n",
    "    full_src_bbox = Bbox(full_src_offset, full_src_offset+full_src_size)\n",
    "    src_bbox = Bbox.from_slices(src.slices_from_global_coords(full_src_bbox))\n",
    "    src_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_src_bbox))\n",
    "    dst_bboxes = []\n",
    "    dst_mask_bboxes = []\n",
    "    for z in [-1,1]:\n",
    "        full_dst_bbox = full_src_bbox + [0,0,z]\n",
    "        dst_bbox = Bbox.from_slices(src.slices_from_global_coords(full_dst_bbox))\n",
    "        dst_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_dst_bbox))\n",
    "        dst_bboxes.append(dst_bbox)\n",
    "        dst_mask_bboxes.append(dst_mask_bbox)\n",
    "        \n",
    "    dst = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/optimizer_tests/v01_mask_two_dsts_mip0\", \n",
    "          mip=img_mip, info=src.info, parallel=False, fill_missing=True, non_aligned_writes=True, cdn_cache=False)\n",
    "    dst.commit_info();\n",
    "    \n",
    "    dst_images = []\n",
    "    dst_masks = []\n",
    "    for dst_bbox, dst_mask_bbox in zip(dst_bboxes, dst_mask_bboxes):\n",
    "        dst_slices = dst_bbox.to_slices()\n",
    "        mask_slices = dst_mask_bbox.to_slices()\n",
    "        dst[dst_slices] = src[dst_slices]\n",
    "        \n",
    "        dst_images.append(src[dst_slices][:,:,0,0] / 255.0)\n",
    "        dst_fold = folds[mask_slices][:,:,0,0] / 255.0\n",
    "        dst_crack = cracks[mask_slices][:,:,0,0] / 255.0\n",
    "        dst_mask = resize(np.minimum(dst_fold, dst_crack), dst_bbox.size3()[:2])\n",
    "        dst_masks.append(dst_mask)\n",
    "        \n",
    "        \n",
    "    src_image = src[src_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_fold = folds[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_crack = cracks[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_mask = resize(np.minimum(src_fold, src_crack), src_bbox.size3()[:2])\n",
    "    \n",
    "    field = flow.process(src_image, dst_images, src_mask, dst_masks)\n",
    "    pred = flow.render(src_image, field)\n",
    "    dst[src_bbox.to_slices()] = (pred[0,0,:,:,np.newaxis, np.newaxis]*255).astype(np.uint8)\n",
    "    return field\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_masks_and_two_dsts_crack():\n",
    "    img_mip = 2\n",
    "    mask_mip = 5\n",
    "    src = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/unmasked\", mip=img_mip, \n",
    "                                                                    parallel=2, fill_missing=True)\n",
    "    cracks = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/crack_detector_v3\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)\n",
    "    folds = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/fold_detector_v1\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)    \n",
    "    flow = Optimizer(ndownsamples=5, currn=5, avgn=20, lambda1=0.5, lr=0.1, eps=0.001, min_iter=100, max_iter=5000)\n",
    "    full_src_offset = np.array([102320, 111106, 526])\n",
    "    full_src_size = np.array([2048, 2048, 1])\n",
    "    full_src_bbox = Bbox(full_src_offset, full_src_offset+full_src_size)\n",
    "    src_bbox = Bbox.from_slices(src.slices_from_global_coords(full_src_bbox))\n",
    "    src_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_src_bbox))\n",
    "    dst_bboxes = []\n",
    "    dst_mask_bboxes = []\n",
    "    for z in [-1,1]:\n",
    "        full_dst_bbox = full_src_bbox + [0,0,z]\n",
    "        dst_bbox = Bbox.from_slices(src.slices_from_global_coords(full_dst_bbox))\n",
    "        dst_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_dst_bbox))\n",
    "        dst_bboxes.append(dst_bbox)\n",
    "        dst_mask_bboxes.append(dst_mask_bbox)\n",
    "        \n",
    "    dst = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/optimizer_tests/v01_mask_two_dsts\", \n",
    "          mip=img_mip, info=src.info, parallel=False, fill_missing=True, non_aligned_writes=True, cdn_cache=False)\n",
    "    dst.commit_info();\n",
    "    \n",
    "    dst_images = []\n",
    "    dst_masks = []\n",
    "    for dst_bbox, dst_mask_bbox in zip(dst_bboxes, dst_mask_bboxes):\n",
    "        dst_slices = dst_bbox.to_slices()\n",
    "        mask_slices = dst_mask_bbox.to_slices()\n",
    "        dst[dst_slices] = src[dst_slices]\n",
    "        \n",
    "        dst_images.append(src[dst_slices][:,:,0,0] / 255.0)\n",
    "        dst_fold = folds[mask_slices][:,:,0,0] / 255.0\n",
    "        dst_crack = cracks[mask_slices][:,:,0,0] / 255.0\n",
    "        dst_mask = resize(np.minimum(dst_fold, dst_crack), dst_bbox.size3()[:2])\n",
    "        dst_masks.append(dst_mask)\n",
    "        \n",
    "        \n",
    "    src_image = src[src_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_fold = folds[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_crack = cracks[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "    src_mask = resize(np.minimum(src_fold, src_crack), src_bbox.size3()[:2])\n",
    "    \n",
    "    src_mask = np.ones_like(src_mask) * ((src_mask < 6/255.0) | (src_mask > 20/255.0))\n",
    "    \n",
    "    field = flow.process(src_image, dst_images, src_mask, dst_masks)\n",
    "    pred = flow.render(src_image, field)\n",
    "    dst[src_bbox.to_slices()] = (pred[0,0,:,:,np.newaxis, np.newaxis]*255).astype(np.uint8)\n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_gt_masks_and_two_dsts():\n",
    "    mip = 2\n",
    "    src = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/unmasked\", mip=mip, \n",
    "                                                                    parallel=2, fill_missing=True)\n",
    "    mask = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/ground_truth\", mip=mip,\n",
    "                                                                     parallel=2, fill_missing=True)\n",
    "    dst = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/optimizer_tests/v02_ground_truth_masks_two_dsts\", \n",
    "          mip=mip, info=src.info, parallel=False, fill_missing=True, non_aligned_writes=True, cdn_cache=False)\n",
    "    dst.commit_info();\n",
    "    flow = Optimizer(ndownsamples=5, currn=5, avgn=20, lambda1=0.5, lr=0.1, eps=0.001, min_iter=100, max_iter=5000)\n",
    "    offsets = [Vec(102320, 111106, 526), (102716, 107077, 526)]\n",
    "    full_src_size = np.array([2048, 2048, 1])\n",
    "    for full_src_offset in offsets:\n",
    "        full_src_bbox = Bbox(full_src_offset, full_src_offset+full_src_size)\n",
    "        src_bbox = Bbox.from_slices(src.slices_from_global_coords(full_src_bbox))\n",
    "        dst_bboxes = []\n",
    "        for z in [-1,1]:\n",
    "            full_dst_bbox = full_src_bbox + [0,0,z]\n",
    "            dst_bbox = Bbox.from_slices(src.slices_from_global_coords(full_dst_bbox))\n",
    "            dst_bboxes.append(dst_bbox)\n",
    "\n",
    "        dst_images = []\n",
    "        dst_masks = []\n",
    "        for dst_bbox in dst_bboxes:\n",
    "            dst_slices = dst_bbox.to_slices()\n",
    "            dst[dst_slices] = src[dst_slices]\n",
    "\n",
    "            dst_images.append(src[dst_slices][:,:,0,0] / 255.0)\n",
    "            dst_mask = (mask[dst_slices][:,:,0,0] == 0) / 1.0\n",
    "            dst_masks.append(dst_mask)\n",
    "\n",
    "\n",
    "        src_image = src[src_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "        src_mask = (mask[src_bbox.to_slices()][:,:,0,0] == 0) / 1.0\n",
    "\n",
    "        field = flow.process(src_image, dst_images, src_mask, dst_masks)\n",
    "        pred = flow.render(src_image, field)\n",
    "        dst[src_bbox.to_slices()] = (pred[0,0,:,:,np.newaxis, np.newaxis]*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def without_masks_and_two_dsts():\n",
    "    mip = 2\n",
    "    src = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/unmasked\", mip=mip, \n",
    "                                                                    parallel=2, fill_missing=True)\n",
    "    mask = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/ground_truth\", mip=mip,\n",
    "                                                                     parallel=2, fill_missing=True)\n",
    "    dst = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/optimizer_tests/v02_without_masks_two_dsts\", \n",
    "          mip=mip, info=src.info, parallel=False, fill_missing=True, non_aligned_writes=True, cdn_cache=False)\n",
    "    dst.commit_info();\n",
    "    flow = Optimizer(ndownsamples=5, currn=5, avgn=20, lambda1=0.5, lr=0.1, eps=0.001, min_iter=100, max_iter=5000)\n",
    "    offsets = [Vec(102320, 111106, 526), (102716, 107077, 526)]\n",
    "    full_src_size = np.array([2048, 2048, 1])\n",
    "    for full_src_offset in offsets:\n",
    "        full_src_bbox = Bbox(full_src_offset, full_src_offset+full_src_size)\n",
    "        src_bbox = Bbox.from_slices(src.slices_from_global_coords(full_src_bbox))\n",
    "        dst_bboxes = []\n",
    "        for z in [-1,1]:\n",
    "            full_dst_bbox = full_src_bbox + [0,0,z]\n",
    "            dst_bbox = Bbox.from_slices(src.slices_from_global_coords(full_dst_bbox))\n",
    "            dst_bboxes.append(dst_bbox)\n",
    "\n",
    "        dst_images = []\n",
    "        dst_masks = []\n",
    "        for dst_bbox in dst_bboxes:\n",
    "            dst_slices = dst_bbox.to_slices()\n",
    "            dst[dst_slices] = src[dst_slices]\n",
    "\n",
    "            dst_image = src[dst_slices][:,:,0,0] / 255.0\n",
    "            dst_images.append(dst_image)\n",
    "            # dst_mask = (mask[dst_slices][:,:,0,0] == 0) / 1.0\n",
    "            dst_mask = np.ones_like(dst_image)\n",
    "            dst_masks.append(dst_mask)\n",
    "\n",
    "\n",
    "        src_image = src[src_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "        # src_mask = (mask[src_bbox.to_slices()][:,:,0,0] == 0) / 1.0\n",
    "        src_mask = np.ones_like(src_image)\n",
    "\n",
    "        field = flow.process(src_image, dst_images, src_mask, dst_masks)\n",
    "        pred = flow.render(src_image, field)\n",
    "        dst[src_bbox.to_slices()] = (pred[0,0,:,:,np.newaxis, np.newaxis]*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_masks_and_two_dsts_more_locations():\n",
    "    img_mip = 2\n",
    "    mask_mip = 5\n",
    "    src = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/unmasked\", mip=img_mip, \n",
    "                                                                    parallel=2, fill_missing=True)\n",
    "    cracks = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/crack_detector_v3\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)\n",
    "    folds = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/mask/fold_detector_v1\", mip=mask_mip,\n",
    "                                                                     parallel=2, fill_missing=True)    \n",
    "    dst = CloudVolume(\"gs://neuroglancer/basil_v0/son_of_alignment/v3.04/optimizer_tests/v01_mask_two_dsts\", \n",
    "          mip=img_mip, info=src.info, parallel=False, fill_missing=True, non_aligned_writes=True, cdn_cache=False)\n",
    "    dst.commit_info();\n",
    "    flow = Optimizer(ndownsamples=5, currn=5, avgn=20, lambda1=0.5, lr=0.1, eps=0.001, min_iter=100, max_iter=5000)\n",
    "    offsets = [Vec(191721, 139068, 528),    # consecutive folds\n",
    "               Vec(196097, 177069, 526),    # consecutive folds\n",
    "               Vec(179301, 81627, 529),     # big crack\n",
    "               Vec(167572, 73149, 522),     # track mark, no masks\n",
    "               Vec(146350, 204341, 524),    # consecutive cracks\n",
    "               Vec(130159, 162051, 525)     # consecutive cracks\n",
    "              ]\n",
    "    full_src_size = np.array([2048, 2048, 1])\n",
    "    for full_src_offset in offsets:\n",
    "        full_src_bbox = Bbox(full_src_offset, full_src_offset+full_src_size)\n",
    "        src_bbox = Bbox.from_slices(src.slices_from_global_coords(full_src_bbox))\n",
    "        src_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_src_bbox))\n",
    "        dst_bboxes = []\n",
    "        dst_mask_bboxes = []\n",
    "        for z in [-1,1]:\n",
    "            full_dst_bbox = full_src_bbox + [0,0,z]\n",
    "            dst_bbox = Bbox.from_slices(src.slices_from_global_coords(full_dst_bbox))\n",
    "            dst_mask_bbox = Bbox.from_slices(folds.slices_from_global_coords(full_dst_bbox))\n",
    "            dst_bboxes.append(dst_bbox)\n",
    "            dst_mask_bboxes.append(dst_mask_bbox)\n",
    "\n",
    "        dst_images = []\n",
    "        dst_masks = []\n",
    "        for dst_bbox, dst_mask_bbox in zip(dst_bboxes, dst_mask_bboxes):\n",
    "            dst_slices = dst_bbox.to_slices()\n",
    "            mask_slices = dst_mask_bbox.to_slices()\n",
    "            dst[dst_slices] = src[dst_slices]\n",
    "\n",
    "            dst_images.append(src[dst_slices][:,:,0,0] / 255.0)\n",
    "            dst_fold = folds[mask_slices][:,:,0,0] / 255.0\n",
    "            dst_crack = cracks[mask_slices][:,:,0,0] / 255.0\n",
    "            crack_max = np.max(dst_crack * (dst_crack < 20/255.0))\n",
    "            crack_min = max(1, crack_max-3)\n",
    "            dst_crack = np.ones_like(dst_crack) * ((dst_crack < crack_min) | (dst_crack > crack_max))\n",
    "            dst_mask = resize(np.minimum(dst_fold, dst_crack), dst_bbox.size3()[:2])\n",
    "            dst_masks.append(dst_mask)\n",
    "\n",
    "\n",
    "        src_image = src[src_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "        src_fold = folds[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "        src_crack = cracks[src_mask_bbox.to_slices()][:,:,0,0] / 255.0\n",
    "        crack_max = np.max(src_crack * (src_crack < 20/255.0))\n",
    "        crack_min = max(1, crack_max-3)\n",
    "        src_crack = np.ones_like(src_crack) * ((src_crack < crack_min) | (src_crack > crack_max))\n",
    "        src_mask = resize(np.minimum(src_fold, src_crack), src_bbox.size3()[:2])\n",
    "\n",
    "        field = flow.process(src_image, dst_images, src_mask, dst_masks)\n",
    "        pred = flow.render(src_image, field)\n",
    "        dst[src_bbox.to_slices()] = (pred[0,0,:,:,np.newaxis, np.newaxis]*255).astype(np.uint8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
