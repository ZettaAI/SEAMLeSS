
{
    "default": {
        "name": {"data":"Crackflow_label_2", "type": "str", "description": "Name of the experiment"},
        "hypothesis": {"data": "Crack and fold corrector", "type":"str", "description": "What should you figure out running this experiment"},
        "identity_init" :{"data": false, "type": "bool", "description":"Initialize as Identity"},
        "resize": {"data": 4, "type": "int", "description": "Resize images"},
        "dilation_rate": {"data": 1, "type": "int", "description": "Global Dilation rate"},
        "aligned": {"data": 0, "type": "int", "description": "Define the data type" },
        "linear": {"data": false, "type": "bool", "description": "Decide if the convolution is linear or not" },
        "output_layer": {"data": 1, "type": "int", "description": "Decide output channel" },

        "radius": {"data": 5, "type": "int", "description": "Maximum radius for finding second" },
        "mean_over_batch": {"data": true, "type": "bool", "description": "Take the mean over the batch otherwise min" },
        "lambd": {"data": -0.5, "type": "float", "description": "Lambda for mixed loss" },
        "eps": {"data": 0.0001, "type": "float", "description": "small number" },
        "loss_type": {"data": "dist", "type": "str", "description": "Define the loss format either 'dist' or 'ratio' " },
        "loss_form": {"data": "minus", "type": "str", "description": "Define the loss formulae to minimize over {'minus', 'inverse', 'log'}" },
        "softmax": {"data": false, "type": "bool", "description": "Use Softmax"},

        "train_file": {"data":["data/tf/crackflow_label_train.tfrecords"], "type": "str", "description": "Training dataset"},
        "test_file": {"data":["data/tf/bad_trainset_24000_612_324.tfrecords"], "type": "str", "description": "Testing dataset"},

        "lambda_1": {"data": 0,"type":"int", "description": "Trade off for smoothness factor"},
        "lambda_2": {"data": 10000,"type":"int", "description": "Trade off for smoothness factor"},
        "levels": {"data": 4,"type":"int", "description": "Pyramid Levels"},
        "learning_rate": {"data": 0.0001, "type": "float", "description": "Learning rate"},
        "log_iterations": {"data": 50, "type": "int", "description": "Tensorflow log level"},
        "batch_size": {"data": 8, "type": "int", "description": "Batch size during training"},

        "momentum": {"data": 0.9, "type": "float", "description": "Learning momentum"},
        "decay": {"data": 0.75, "type": "float", "description": "Learning momentum"},
        "decay_steps": {"data": 1000, "type": "int", "description": "Learning momentum"},
        "steps": {"data": 100000, "type": "int", "description":  "Number of steps to complete the training"},
        "epoch_size": {"data": 16, "type": "int", "description": "Epoch size during training"},
        "eval_batch_size": {"data": 2, "type": "int", "description": "Batch size during evaluation"},
        "optimizer": {"data": "Adam", "type": "str", "description": "Optimizer Name (Adam, Adagrad, etc)"},
        "loglevel": {"data": 20, "type": "int", "description": "Tensorflow log level"},
        "output_layer": {"data": 8, "type": "int", "description": "output layer of UNET"},

        "eval_iterations": {"data": 1000, "type": "int", "description": "Tensorflow log level"},
        "resize_conv": {"data": true, "type":"int","description": "use resize convolutions otherwise deconvolutions"},


        "kernels_shape": {
            "data":  [[3,3,1,16],
                      [3,3,16,32],
                      [3,3,32,64],
                      [3,3,64,128]],
            "type": "array of int", "description": "Kernel description"},

        "testing_steps": {"data": 100, "type": "int", "description": "testing_steps"},

        "features": {
            "data": {
                "image": {"in_width": 312, "width": 256},
                "target": {"in_width": 312, "width": 256},
                "label": {"in_width": 312, "width": 256}

            }, "type": "dict", "description": "Structure of input features"},

        "augmentation":{
            "data": {
                "flipping": true,
                "random_brightness": false,
                "random_elastic_transform": true
            }, "type": "dict", "description": "augmetation"}
    },

    "preprocessing": {
        "tfrecord_train_dest": {"data":"data/tf/pinky_training.tfrecords", "type": "str", "description": "Destination of training set"},

        "cloud_src": {"data":"gs://neuroglancer/pinky100_v0/image_single_slices/", "type": "str", "description": "Cloud directory"},
        "cloud_mip": {"data": 4, "type": "str", "description": "MIP level for neuroglancer"},
        "threads": {"data":16, "type": "str", "description": "Number of threads for data collection"},
        "width": {"data":224, "type": "str", "description": "width of the image"},
        "scale": {"data":1, "type": "str", "description": "scaling factor"},
        "features": {
            "data": {
                "search_raw": {"in_width": 612, "width": 384},
                "template_raw": {"in_width": 612, "width": 120}
            }, "type": "dict", "description": "Structure of input features"}
    },
    "evaluation":{
        "batch_size": {"data": 8, "type": "int", "description": "Batch size during training"},
        "train_file": {"data":["data/tf/bad_trainset_24000_612_324.tfrecords"], "type": "str", "description": "Testing dataset"},
        "features": {
            "data": {
                "search_raw": {"in_width": 612, "width": 512},
                "template_raw": {"in_width": 324, "width": 120}
            }, "type": "dict", "description": "Structure of input features"},

        "augmentation":{
            "data": {
                "flipping": false,
                "random_brightness": false,
                "random_elastic_transform": false
            }, "type": "dict", "description": "augmentation"}

    }
}
